# ğŸ¤– Mistral AI Connector

Connecteur central et standard pour Mistral AI sur la plateforme agent-pf.

## ğŸ“‹ Description

Ce service fournit une interface unifiÃ©e et centralisÃ©e pour que tous les agents de la plateforme puissent interagir avec Mistral AI. Il expose une API REST complÃ¨te permettant :

- ğŸ’¬ **Chat Completion** : Conversations contextuelles avec l'IA
- ğŸ”¢ **Embeddings** : Transformation de texte en vecteurs numÃ©riques
- ğŸ“Š **Gestion des modÃ¨les** : Liste et informations sur les modÃ¨les disponibles

## ğŸš€ DÃ©marrage rapide

### PrÃ©requis

- Docker et Docker Compose
- Une clÃ© API Mistral AI ([obtenir une clÃ©](https://console.mistral.ai/))

### Installation

1. **Configurer la clÃ© API**

```bash
# Copier le fichier d'exemple
cp .env.example .env

# Ã‰diter le fichier .env et ajouter votre clÃ© API
MISTRAL_API_KEY=your_actual_api_key_here
```

2. **DÃ©marrer le service**

```bash
# Via Docker Compose (depuis la racine du projet)
docker-compose up -d mistral-connector

# Ou en dÃ©veloppement local
pip install -r requirements.txt
uvicorn app.main:app --reload
```

3. **VÃ©rifier que le service fonctionne**

```bash
curl http://localhost:8005/health
```

## ğŸ“š Utilisation

### AccÃ©der Ã  la documentation

- **Swagger UI** : http://localhost:8005/docs
- **ReDoc** : http://localhost:8005/redoc

### Exemples d'utilisation

#### Chat Completion

```bash
curl -X POST "http://localhost:8005/api/v1/mistral/chat" \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {"role": "user", "content": "Explique-moi la photosynthÃ¨se en termes simples"}
    ],
    "temperature": 0.7,
    "max_tokens": 500
  }'
```

#### Conversation multi-tours

```bash
curl -X POST "http://localhost:8005/api/v1/mistral/chat" \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {"role": "system", "content": "Tu es un expert en physique"},
      {"role": "user", "content": "Qu'\''est-ce qu'\''un trou noir ?"},
      {"role": "assistant", "content": "Un trou noir est une rÃ©gion de l'\''espace..."},
      {"role": "user", "content": "Comment se forment-ils ?"}
    ],
    "model": "mistral-medium-latest"
  }'
```

#### GÃ©nÃ©ration d'embeddings

```bash
curl -X POST "http://localhost:8005/api/v1/mistral/embeddings" \
  -H "Content-Type: application/json" \
  -d '{
    "input": [
      "Premier document Ã  vectoriser",
      "DeuxiÃ¨me document Ã  comparer"
    ]
  }'
```

#### Liste des modÃ¨les disponibles

```bash
curl http://localhost:8005/api/v1/mistral/models
```

### Utilisation avec une clÃ© API personnalisÃ©e

Vous pouvez fournir une clÃ© API diffÃ©rente pour chaque requÃªte via le header `X-API-Key` :

```bash
curl -X POST "http://localhost:8005/api/v1/mistral/chat" \
  -H "X-API-Key: your_custom_api_key" \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [{"role": "user", "content": "Hello!"}]
  }'
```

## ğŸ Utilisation depuis Python

### Installation du client

```bash
pip install httpx
```

### Exemple de code

```python
import httpx

# Chat simple
response = httpx.post(
    "http://localhost:8005/api/v1/mistral/chat",
    json={
        "messages": [
            {"role": "user", "content": "Bonjour, comment vas-tu ?"}
        ],
        "temperature": 0.7
    }
)

result = response.json()
if result["success"]:
    print(result["message"]["content"])
else:
    print(f"Erreur: {result['error']}")

# Embeddings
response = httpx.post(
    "http://localhost:8005/api/v1/mistral/embeddings",
    json={
        "input": ["Texte Ã  vectoriser", "Autre texte"]
    }
)

embeddings = response.json()
if embeddings["success"]:
    print(f"Vecteurs gÃ©nÃ©rÃ©s: {len(embeddings['embeddings'])}")
```

## ğŸ¯ ModÃ¨les disponibles

| ModÃ¨le | Description | Cas d'usage |
|--------|-------------|-------------|
| `mistral-tiny` | Rapide et Ã©conomique | TÃ¢ches simples, classification |
| `mistral-small-latest` | Ã‰quilibrÃ© (par dÃ©faut) | Usage gÃ©nÃ©ral |
| `mistral-medium-latest` | Plus puissant | TÃ¢ches complexes |
| `mistral-large-latest` | Le plus performant | Raisonnement avancÃ© |
| `mistral-embed` | Embeddings | Recherche sÃ©mantique, similaritÃ© |

## âš™ï¸ Configuration

### Variables d'environnement

| Variable | Description | DÃ©faut |
|----------|-------------|--------|
| `MISTRAL_API_KEY` | ClÃ© API Mistral (obligatoire) | - |
| `ENVIRONMENT` | Environnement (production/development) | production |
| `CORS_ORIGINS` | Origines CORS autorisÃ©es | * |
| `DEFAULT_MODEL` | ModÃ¨le par dÃ©faut | mistral-small-latest |
| `DEFAULT_MAX_TOKENS` | Nombre max de tokens | 1024 |
| `DEFAULT_TEMPERATURE` | TempÃ©rature par dÃ©faut | 0.7 |

### ParamÃ¨tres de requÃªte

#### Chat Completion

- `messages` (obligatoire) : Liste des messages de la conversation
- `model` (optionnel) : ModÃ¨le Ã  utiliser
- `temperature` (0.0-2.0) : ContrÃ´le la crÃ©ativitÃ©
- `max_tokens` : Limite de tokens pour la rÃ©ponse
- `top_p` (0.0-1.0) : Top-p sampling
- `safe_prompt` (bool) : Active le mode safe prompt

#### Embeddings

- `input` (obligatoire) : Liste des textes Ã  vectoriser
- `model` (optionnel) : ModÃ¨le d'embedding (dÃ©faut: mistral-embed)

## ğŸ—ï¸ Architecture

```
services/mistral-connector/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # Application FastAPI
â”‚   â”œâ”€â”€ config.py            # Configuration
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ mistral_models.py   # SchÃ©mas Pydantic
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ mistral_service.py  # Logique mÃ©tier
â”‚   â””â”€â”€ routers/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ mistral.py       # Endpoints API
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_mistral.py
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ API.md
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

## ğŸ§ª Tests

```bash
# Installer les dÃ©pendances de test
pip install -r requirements.txt

# ExÃ©cuter les tests
pytest tests/

# Avec couverture
pytest tests/ --cov=app --cov-report=html
```

## ğŸ”’ SÃ©curitÃ©

- âœ… ClÃ© API stockÃ©e en variable d'environnement
- âœ… Support de clÃ©s API par requÃªte
- âœ… Validation des entrÃ©es via Pydantic
- âœ… Gestion des erreurs complÃ¨te
- âœ… Logs dÃ©taillÃ©s
- âœ… Utilisateur non-root dans Docker

## ğŸ› DÃ©pannage

### Le service ne dÃ©marre pas

1. VÃ©rifiez que la clÃ© API est configurÃ©e dans `.env`
2. VÃ©rifiez les logs : `docker-compose logs mistral-connector`
3. VÃ©rifiez que le port 8005 n'est pas dÃ©jÃ  utilisÃ©

### Erreur "Client Mistral non initialisÃ©"

La clÃ© API n'est pas configurÃ©e. VÃ©rifiez votre fichier `.env` ou fournissez une clÃ© via le header `X-API-Key`.

### Erreur de timeout

Augmentez le timeout dans votre client HTTP ou rÃ©duisez `max_tokens`.

## ğŸ“ Licence

Voir le fichier LICENSE Ã  la racine du projet.

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Veuillez suivre le processus standard de PR.

## ğŸ“ Support

Pour toute question ou problÃ¨me, ouvrez une issue sur le dÃ©pÃ´t GitHub.

---

DÃ©veloppÃ© avec â¤ï¸ pour la plateforme agent-pf
