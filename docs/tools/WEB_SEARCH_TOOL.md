# ğŸ”§ Web Search Tool

## ğŸ“‹ Vue d'ensemble

Le Web Search Tool est une API REST pour effectuer des recherches web et extraire du contenu de pages internet. Il supporte plusieurs moteurs de recherche (DuckDuckGo, Google, Bing) avec configuration flexible du nombre de rÃ©sultats, du langage et de la sÃ©curitÃ© du contenu.

**CapacitÃ©s principales :**
- Recherche web sur DuckDuckGo, Google, Bing
- Configuration du nombre de rÃ©sultats
- Support multilingue
- Safe search configurable
- Extraction de texte des pages web
- Extraction de liens et images
- RÃ©cupÃ©ration des mÃ©tadonnÃ©es
- Timeout configurable pour les requÃªtes

## ğŸ—ï¸ Architecture

```
web-search-tool/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # Application FastAPI
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ search_models.py # ModÃ¨les Pydantic
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ search.py        # Endpoints API
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ search_service.py # Logique mÃ©tier
â”‚   â””â”€â”€ middleware/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ auth.py          # Authentification
â”œâ”€â”€ tests/
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ API.md               # Documentation dÃ©taillÃ©e
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

**DÃ©pendances principales :**
- FastAPI 0.104+
- httpx 0.25+
- BeautifulSoup4 4.12+
- Pydantic 2.5+

## ğŸ”Œ API REST

### Recherche web

```bash
# POST /api/v1/search
curl -X POST "http://localhost:8002/api/v1/search" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "FastAPI tutorial",
    "engine": "duckduckgo",
    "max_results": 5,
    "safe_search": true,
    "lang": "en"
  }'

# RÃ©ponse JSON
{
  "success": true,
  "query": "FastAPI tutorial",
  "engine": "duckduckgo",
  "results": [
    {
      "title": "FastAPI - Modern Python Web Framework",
      "url": "https://fastapi.tiangolo.com",
      "snippet": "FastAPI is a modern, fast...",
      "rank": 1
    }
  ],
  "total_results": 5
}
```

```python
# Python
import requests

response = requests.post(
    "http://localhost:8002/api/v1/search",
    json={
        "query": "Python web development",
        "engine": "duckduckgo",
        "max_results": 5
    }
)

results = response.json()
for result in results["results"]:
    print(f"{result['title']}")
    print(f"{result['url']}")
    print()
```

### Extraction de contenu de page web

```bash
# POST /api/v1/search/extract
curl -X POST "http://localhost:8002/api/v1/search/extract" \
  -H "Content-Type: application/json" \
  -d '{
    "url": "https://example.com",
    "extract_text": true,
    "extract_links": true,
    "extract_images": true,
    "extract_metadata": true
  }'

# RÃ©ponse JSON
{
  "success": true,
  "url": "https://example.com",
  "metadata": {
    "title": "Example Domain",
    "description": "Example Domain. This domain...",
    "og_image": "https://example.com/image.jpg"
  },
  "text": "Example Domain\nThis domain is for use...",
  "links": [
    {
      "text": "More information",
      "url": "https://www.iana.org/domains/example"
    }
  ],
  "images": [
    {
      "src": "https://example.com/img.png",
      "alt": "Example image"
    }
  ]
}
```

### Recherche avec extraction intÃ©grÃ©e

```bash
# POST /api/v1/search/with-extraction
curl -X POST "http://localhost:8002/api/v1/search/with-extraction" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Python best practices",
    "engine": "duckduckgo",
    "max_results": 3,
    "extract_from_results": true
  }'

# RÃ©ponse avec contenu extrait de chaque rÃ©sultat
{
  "success": true,
  "query": "Python best practices",
  "results": [
    {
      "title": "PEP 8 Style Guide",
      "url": "https://pep8.org",
      "snippet": "...",
      "extracted_content": {
        "text": "...",
        "links": [...]
      }
    }
  ]
}
```

## ğŸš€ Utilisation

### Installation locale

```bash
# Naviguer au rÃ©pertoire
cd /home/user/agent-pf/tools/web-search-tool

# Installer les dÃ©pendances
pip install -r requirements.txt

# Lancer l'API
uvicorn app.main:app --host 0.0.0.0 --port 8002 --reload
```

### DÃ©ploiement Docker

```bash
# Build l'image
docker build -t web-search-tool .

# Lancer le container
docker run -p 8002:8000 web-search-tool

# Ou via docker-compose
docker-compose up -d web-search-tool
```

### Documentation interactive

- **Swagger UI** : http://localhost:8002/docs
- **ReDoc** : http://localhost:8002/redoc
- **OpenAPI JSON** : http://localhost:8002/openapi.json

## âš™ï¸ Configuration

### Variables d'environnement

```env
# Environnement
ENVIRONMENT=production
API_PORT=8002

# Authentification
SKIP_AUTH=false
AUTHENTIK_URL=http://authentik-server:9000

# CORS
CORS_ORIGINS=*

# Search
DEFAULT_ENGINE=duckduckgo  # duckduckgo, google, bing
DEFAULT_TIMEOUT=10
MAX_RESULTS=50
```

### Moteurs de recherche supportÃ©s

- **DuckDuckGo** (recommandÃ©) - Plus tolÃ©rant aux requÃªtes automatisÃ©es
- **Google** - Peut bloquer les requÃªtes de scraping
- **Bing** - Performance acceptable

### Mode dÃ©veloppement

```bash
export ENVIRONMENT=development
export SKIP_AUTH=true
```

## ğŸ› Troubleshooting

### Recherche sans rÃ©sultats

```bash
# Essayer un moteur diffÃ©rent
curl -X POST "http://localhost:8002/api/v1/search" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "votre requÃªte",
    "engine": "bing"
  }'

# Essayer avec moins de rÃ©sultats
{
  "query": "votre requÃªte",
  "max_results": 3
}
```

### Service bloquÃ© par le moteur

Les moteurs comme Google et Bing peuvent bloquer les requÃªtes automatisÃ©es. Solutions :

1. Utiliser DuckDuckGo (recommandÃ©)
2. RÃ©duire la frÃ©quence des requÃªtes
3. Utiliser un proxy ou VPN
4. Augmenter le timeout

```bash
# Essayer avec DuckDuckGo
{
  "query": "votre requÃªte",
  "engine": "duckduckgo"
}
```

### Timeout sur extraction de contenu

```bash
# Augmenter le timeout
{
  "url": "https://example.com",
  "timeout": 30  # secondes
}

# Ou rÃ©duire les extractions demandÃ©es
{
  "url": "https://example.com",
  "extract_text": true,
  "extract_links": false,
  "extract_images": false
}
```

### Extraction de contenu vide

- Le site peut Ãªtre protÃ©gÃ© (JavaScript, etc.)
- Le site peut bloquer les bots
- Le contenu peut Ãªtre dans des iframes

```bash
# VÃ©rifier que le site est accessible
curl -I https://example.com

# Essayer avec un User-Agent personnalisÃ©
# (intÃ©grÃ© automatiquement dans les requÃªtes)
```

### Authentification refusÃ©e

```bash
# VÃ©rifier le token Bearer
curl -X POST "http://localhost:8002/api/v1/search" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{...}'
```

## ğŸ“ Exemples pratiques

### Recherche d'actualitÃ©s

```python
import requests

response = requests.post(
    "http://localhost:8002/api/v1/search",
    json={
        "query": "Python 3.12 release",
        "engine": "duckduckgo",
        "max_results": 10,
        "safe_search": True
    }
)

for result in response.json()["results"]:
    print(f"- {result['title']}")
    print(f"  {result['url']}")
```

### Extraction et analyse

```python
import requests

# Extraire du contenu de documentation
response = requests.post(
    "http://localhost:8002/api/v1/search/extract",
    json={
        "url": "https://docs.python.org",
        "extract_text": True,
        "extract_links": True
    }
)

content = response.json()
print(f"Titre: {content['metadata']['title']}")
print(f"Nombre de liens: {len(content['links'])}")
```

---

**Service** : Web Search Tool
**Port** : 8002
**Environnement** : Production / DÃ©veloppement
**Authentification** : Bearer Token / Authentik
