# üîß Prompt Moderation Tool

## üìã Vue d'ensemble

Le Prompt Moderation Tool est une API REST pour la mod√©ration et la s√©curisation des prompts utilisateurs. Il d√©tecte et signale les contenus potentiellement probl√©matiques (profanit√©, donn√©es sensibles, contenu confidentiel, contenu inappropri√©), analyse les risques associ√©s et peut fournir une version d√©sinfect√©e du prompt pour un usage s√ªr.

**Capacit√©s principales :**
- D√©tection de profanit√© et langage offensant
- Identification d'utilisation personnelle vs professionnelle
- D√©tection de donn√©es sensibles (emails, num√©ros, donn√©es perso)
- D√©tection de contenu confidentiel
- D√©tection de contenu inappropri√©
- Mod√©ration en mode strict configurable
- Classification des risques (safe, low, medium, high)
- G√©n√©ration de prompts d√©sinfect√©s
- Rapports d√©taill√©s avec patterns correspondants

## üèóÔ∏è Architecture

```
prompt-moderation-tool/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ main.py              # Application FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ config.py            # Configuration
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ moderation_models.py # Mod√®les Pydantic
‚îÇ   ‚îú‚îÄ‚îÄ routers/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ moderation.py    # Endpoints API
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ moderation_service.py # Logique de mod√©ration
‚îÇ   ‚îî‚îÄ‚îÄ middleware/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îî‚îÄ‚îÄ auth.py          # Authentification
‚îú‚îÄ‚îÄ tests/
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

**D√©pendances principales :**
- FastAPI 0.104+
- Pydantic 2.5+
- python-dotenv

## üîå API REST

### Mod√©rer un prompt

```bash
# POST /api/v1/moderate
curl -X POST "http://localhost:8013/api/v1/moderate" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Pouvez-vous analyser les donn√©es dans le fichier C:\\Users\\John\\Confidential\\report.pdf?",
    "strict_mode": true
  }'

# R√©ponse JSON
{
  "success": true,
  "approved": false,
  "flags": [
    {
      "reason": "sensitive_data",
      "severity": "high",
      "details": "Chemin de fichier local d√©tect√© contenant des informations potentiellement sensibles",
      "matched_patterns": ["C:\\Users\\John\\Confidential\\"]
    },
    {
      "reason": "confidential_content",
      "severity": "medium",
      "details": "R√©f√©rence √† un contenu marqu√© comme confidentiel",
      "matched_patterns": ["Confidential"]
    }
  ],
  "overall_risk_level": "high",
  "message": "Le prompt contient des donn√©es sensibles et un contenu confidentiel. Approbation refus√©e.",
  "sanitized_prompt": "Pouvez-vous analyser les donn√©es dans le fichier [FICHIER SUPPRIM√â]?"
}
```

```python
# Python
import requests

response = requests.post(
    "http://localhost:8013/api/v1/moderate",
    json={
        "prompt": "Pouvez-vous analyser mon mot de passe 'SecurePass123'?",
        "strict_mode": True
    }
)

moderation = response.json()
print(f"Approuv√©: {moderation['approved']}")
print(f"Niveau de risque: {moderation['overall_risk_level']}")
print(f"Message: {moderation['message']}")

if not moderation['approved']:
    print(f"Prompt d√©sinfect√©: {moderation['sanitized_prompt']}")
```

### Mod√©ration en mode normal

```bash
# Mode normal (moins strict)
curl -X POST "http://localhost:8013/api/v1/moderate" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Comment cr√©er une pr√©sentation PowerPoint?",
    "strict_mode": false
  }'

# R√©ponse
{
  "success": true,
  "approved": true,
  "flags": [],
  "overall_risk_level": "safe",
  "message": "Prompt approuv√© sans probl√®mes d√©tect√©s.",
  "sanitized_prompt": null
}
```

## Raisons de mod√©ration

| Raison | Description | S√©v√©rit√© |
|--------|-------------|----------|
| `profanity` | Langage offensant, insultes, termes p√©joratifs | Variable |
| `personal_use` | Indicateurs d'utilisation personnelle | Variable |
| `sensitive_data` | Donn√©es personnelles, emails, num√©ros | High |
| `confidential_content` | Marqueurs de contenu confidentiel | Medium |
| `inappropriate_content` | Contenu explicite ou offensant | High |

## Niveaux de risque

| Niveau | Description |
|--------|-------------|
| `safe` | Aucun risque d√©tect√© |
| `low` | Risque minimal, approbation recommand√©e |
| `medium` | Risques mod√©r√©s, v√©rification recommand√©e |
| `high` | Risques significatifs, approbation refus√©e |

## üöÄ Utilisation

### Installation locale

```bash
# Naviguer au r√©pertoire
cd /home/user/agent-pf/tools/prompt-moderation-tool

# Installer les d√©pendances
pip install -r requirements.txt

# Lancer l'API
uvicorn app.main:app --host 0.0.0.0 --port 8013 --reload
```

### D√©ploiement Docker

```bash
# Build l'image
docker build -t prompt-moderation-tool .

# Lancer le container
docker run -p 8013:8013 prompt-moderation-tool

# Ou via docker-compose
docker-compose up -d prompt-moderation-tool
```

### Documentation interactive

- **Swagger UI** : http://localhost:8013/docs
- **ReDoc** : http://localhost:8013/redoc

## ‚öôÔ∏è Configuration

### Variables d'environnement

```env
# Application
APP_NAME=Prompt Moderation Tool
VERSION=1.0.0
ENVIRONMENT=production

# API
API_PORT=8013

# CORS
CORS_ORIGINS=*

# Mod√©ration
STRICT_MODE_DEFAULT=true
PROFANITY_DETECTION=true
SENSITIVE_DATA_DETECTION=true
CONFIDENTIAL_DETECTION=true
```

## üêõ Troubleshooting

### Faux positifs √©lev√©s

- Ajuster les patterns de d√©tection
- Utiliser le mode normal au lieu du mode strict
- Whitelist certains termes

```bash
# Mode normal pour moins de faux positifs
{
  "prompt": "O√π acheter un logiciel confidentiel de bonne qualit√©?",
  "strict_mode": false
}
```

### Contenu dangereux non d√©tect√©

- Augmenter la sensibilit√© avec strict_mode
- V√©rifier les patterns de d√©tection
- Ajouter des signatures suppl√©mentaires

```bash
# Mode strict pour plus de sensibilit√©
{
  "prompt": "Contenu √† v√©rifier",
  "strict_mode": true
}
```

### API inaccessible

```bash
# V√©rifier que le service est en cours d'ex√©cution
curl http://localhost:8013/health

# V√©rifier les logs
docker-compose logs prompt-moderation-tool

# Red√©marrer le service
docker-compose restart prompt-moderation-tool
```

## üìù Exemples pratiques

### Filtrer les donn√©es sensibles

```python
import requests

# Prompt contenant une adresse email
response = requests.post(
    "http://localhost:8013/api/v1/moderate",
    json={
        "prompt": "Contactez mon manager √† john.doe@company.com",
        "strict_mode": True
    }
)

result = response.json()
# approved: false
# overall_risk_level: high
# reason: sensitive_data
# sanitized_prompt: "Contactez mon manager √† [EMAIL SUPPRIM√â]"
```

### V√©rifier la conformit√©

```python
import requests

prompts = [
    "Cr√©er un rapport de ventes",
    "Mon mot de passe est XYZ",
    "Analyser les donn√©es de Q4",
    "Contenu confidentiel √† ne pas partager"
]

for prompt in prompts:
    response = requests.post(
        "http://localhost:8013/api/v1/moderate",
        json={"prompt": prompt, "strict_mode": True}
    )

    result = response.json()
    print(f"'{prompt}'")
    print(f"  Approuv√©: {result['approved']}")
    print(f"  Risque: {result['overall_risk_level']}")
    print()
```

### Pipeline de mod√©ration s√©curis√©

```python
import requests

# 1. Mod√©rer le prompt
moderation = requests.post(
    "http://localhost:8013/api/v1/moderate",
    json={"prompt": user_input, "strict_mode": True}
).json()

# 2. V√©rifier l'approbation
if not moderation['approved']:
    print(f"Prompt rejet√©: {moderation['message']}")
    exit(1)

# 3. Utiliser le prompt d√©sinfect√© si disponible
safe_prompt = moderation.get('sanitized_prompt', user_input)

# 4. Classifier le contenu
classification = requests.post(
    "http://localhost:8014/api/v1/classify",
    json={"prompt": safe_prompt}
).json()

# 5. Proc√©der au traitement
if classification['is_professional']:
    process(safe_prompt)
else:
    print("Contenu non-professionnel d√©tect√©")
```

### Enregistrement des violations

```python
import requests
import json
from datetime import datetime

violations = []

def moderate_and_log(prompt):
    response = requests.post(
        "http://localhost:8013/api/v1/moderate",
        json={"prompt": prompt, "strict_mode": True}
    ).json()

    if not response['approved']:
        violations.append({
            "timestamp": datetime.now().isoformat(),
            "prompt": prompt[:100],  # Stocker les premiers 100 chars
            "risk_level": response['overall_risk_level'],
            "flags": len(response['flags'])
        })

    return response['approved']

# Enregistrer les violations pour audit
with open("violations.log", "w") as f:
    json.dump(violations, f, indent=2)
```

## üìä Cas d'usage

### S√©curisation d'une plateforme SaaS

```python
# Valider tous les inputs utilisateurs
request_payload = {
    "prompt": user_prompt,
    "strict_mode": True
}

moderation = requests.post(
    "http://localhost:8013/api/v1/moderate",
    json=request_payload
).json()

if not moderation['approved']:
    log_security_incident(moderation)
    return {"error": "Request blocked by security policy"}
```

### Conformit√© RGPD

```python
# D√©tecter et supprimer les donn√©es personnelles
moderation = requests.post(
    "http://localhost:8013/api/v1/moderate",
    json={"prompt": user_input, "strict_mode": True}
).json()

# Utiliser le prompt d√©sinfect√© pour la conformit√©
sanitized = moderation.get('sanitized_prompt', user_input)
store_for_logging(sanitized)  # Sauf les donn√©es perso
```

---

**Service** : Prompt Moderation Tool
**Port** : 8013
**Environnement** : Production / D√©veloppement
**Authentification** : CORS configurable
