# Architecture des Agents et Outils - Agent-PF

## ğŸ“‹ Table des MatiÃ¨res

1. [Vue d'Ensemble](#vue-densemble)
2. [Architecture Backend (FastAPI)](#architecture-backend-fastapi)
3. [Architecture Globale](#architecture-globale)
4. [Les Agents Orchestrateurs](#les-agents-orchestrateurs)
5. [Les Tools (Outils)](#les-tools-outils)
6. [Les Connecteurs Centraux](#les-connecteurs-centraux)
7. [Les Briques Graphiques (UI)](#les-briques-graphiques-ui)
8. [Flux de DonnÃ©es Complets](#flux-de-donnÃ©es-complets)
9. [Exemples Pratiques](#exemples-pratiques)
10. [CrÃ©er un Nouvel Agent](#crÃ©er-un-nouvel-agent)

---

## Vue d'Ensemble

**Agent-PF** est une plateforme d'agents IA orchestrÃ©s construite sur une **architecture microservices**. Chaque composant (agent, outil, connecteur) est un service indÃ©pendant qui communique via HTTP/REST.

### Principes Architecturaux

- ğŸ¯ **DÃ©couplage**: Chaque service est autonome avec sa propre responsabilitÃ©
- ğŸ”„ **RÃ©utilisabilitÃ©**: Les tools sont partagÃ©s entre plusieurs agents
- ğŸš€ **ScalabilitÃ©**: Chaque service peut Ãªtre scalÃ© indÃ©pendamment
- ğŸ›¡ï¸ **RÃ©silience**: La dÃ©faillance d'un service n'affecte pas les autres
- ğŸ”§ **MaintenabilitÃ©**: Code organisÃ© et standardisÃ© (FastAPI + Angular)

### Stack Technique

| Composant | Technologie |
|-----------|-------------|
| **Backend** | FastAPI (Python 3.9+) |
| **Frontend** | Angular 17+ |
| **Orchestration** | Docker Compose |
| **Communication** | HTTP/REST (httpx pour async) |
| **Validation** | Pydantic |
| **IA** | Mistral AI, OpenAI |

---

## Architecture Backend (FastAPI)

Tous les services backend (agents, tools, connecteurs) suivent une **architecture en couches** basÃ©e sur FastAPI. Cette architecture sÃ©pare les responsabilitÃ©s en trois couches principales : **Models**, **Services** et **Routers**.

### Vue d'Ensemble des Couches

```mermaid
graph LR
    A[Client HTTP] -->|Request| B[Router]
    B -->|Validation| C[Models Pydantic]
    C -->|Data validÃ©e| D[Service]
    D -->|Appels externes| E[Autres Services]
    D -->|Logique mÃ©tier| D
    D -->|Response| C
    C -->|Serialization| B
    B -->|JSON Response| A

    style B fill:#e1f5ff
    style D fill:#fff4e6
    style C fill:#e8f5e9
```

### Les Trois Couches

#### 1. ğŸ“¦ Models (ModÃ¨les Pydantic)

**RÃ´le** : DÃ©finir les structures de donnÃ©es et la validation

**ResponsabilitÃ©s** :
- âœ… DÃ©finir les schÃ©mas de **requÃªtes** (Request Models)
- âœ… DÃ©finir les schÃ©mas de **rÃ©ponses** (Response Models)
- âœ… **Validation automatique** des donnÃ©es entrantes
- âœ… **SÃ©rialisation/dÃ©sÃ©rialisation** JSON
- âœ… Documentation auto-gÃ©nÃ©rÃ©e (OpenAPI)
- âœ… Type hints pour l'IDE et mypy

**Localisation** : `app/models/[nom].py`

**Exemple Concret** :

```python
# agents/ai-chat-agent/app/models/chat.py

from pydantic import BaseModel, Field
from typing import List, Optional, Literal
from enum import Enum

class AIProvider(str, Enum):
    """Providers IA supportÃ©s"""
    MISTRAL = "mistral"
    OPENAI = "openai"

class ChatMessage(BaseModel):
    """ModÃ¨le d'un message de chat"""
    role: Literal["user", "assistant", "system"]
    content: str = Field(..., min_length=1, description="Contenu du message")

    class Config:
        # Exemple de message pour la doc OpenAPI
        json_schema_extra = {
            "example": {
                "role": "user",
                "content": "Explique-moi les microservices"
            }
        }

class ChatRequest(BaseModel):
    """RequÃªte de chat - validÃ©e automatiquement par FastAPI"""
    messages: List[ChatMessage] = Field(..., min_length=1)
    provider: AIProvider = Field(default=AIProvider.MISTRAL)
    model: Optional[str] = Field(default="mistral-large-latest")
    temperature: float = Field(default=0.7, ge=0.0, le=2.0)
    max_tokens: Optional[int] = Field(default=None, ge=1, le=32000)
    strict_mode: bool = Field(default=False, description="Mode strict de modÃ©ration")

    # ClÃ©s API optionnelles
    mistral_api_key: Optional[str] = None
    openai_api_key: Optional[str] = None

    class Config:
        json_schema_extra = {
            "example": {
                "messages": [
                    {"role": "user", "content": "Bonjour"}
                ],
                "provider": "mistral",
                "model": "mistral-large-latest",
                "temperature": 0.7,
                "strict_mode": False
            }
        }

class ChatResponse(BaseModel):
    """RÃ©ponse de chat - sÃ©rialisÃ©e automatiquement par FastAPI"""
    success: bool
    message: Optional[str] = None
    error: Optional[str] = None
    blocked_reason: Optional[str] = None

    # MÃ©tadonnÃ©es de gouvernance
    moderation_metadata: Optional[dict] = None
    classification_metadata: Optional[dict] = None

    # MÃ©tadonnÃ©es gÃ©nÃ©rales
    metadata: Optional[dict] = None

class ModerationResult(BaseModel):
    """RÃ©sultat de modÃ©ration"""
    is_appropriate: bool
    categories_detected: Optional[List[str]] = []
    severity: Optional[str] = None
    reason: Optional[str] = None
```

**Avantages des Models Pydantic** :
- âœ… Validation automatique (ex: `temperature` doit Ãªtre entre 0 et 2)
- âœ… Messages d'erreur clairs si donnÃ©es invalides
- âœ… Conversion automatique des types
- âœ… Documentation OpenAPI gÃ©nÃ©rÃ©e automatiquement
- âœ… Auto-complÃ©tion dans l'IDE

---

#### 2. ğŸ§  Services (Logique MÃ©tier)

**RÃ´le** : Contenir la logique mÃ©tier et l'orchestration

**ResponsabilitÃ©s** :
- âœ… ImplÃ©menter la **logique mÃ©tier** complexe
- âœ… **Orchestrer** les appels Ã  d'autres services (tools, connecteurs)
- âœ… GÃ©rer les **transformations de donnÃ©es**
- âœ… GÃ©rer les **erreurs** et les **retry**
- âœ… ImplÃ©menter les **workflows** multi-Ã©tapes
- âŒ **NE PAS** gÃ©rer les requÃªtes HTTP directement (c'est le rÃ´le du router)
- âŒ **NE PAS** stocker d'Ã©tat (stateless)

**Localisation** : `app/services/[nom]_service.py`

**Pattern** : Classes avec mÃ©thodes statiques ou de classe (`@classmethod`)

**Exemple Concret** :

```python
# agents/ai-chat-agent/app/services/chat_service.py

import httpx
from typing import Dict, List
from app.config import settings
from app.models.chat import ChatRequest, ChatResponse, ChatMessage

class ChatService:
    """
    Service d'orchestration du chat IA avec gouvernance

    ResponsabilitÃ©s:
    - Orchestrer le workflow complet (classification -> modÃ©ration -> IA)
    - GÃ©rer les appels HTTP aux services dÃ©pendants
    - AgrÃ©ger les mÃ©tadonnÃ©es de gouvernance
    """

    # URLs des services dÃ©pendants (depuis la config)
    PROMPT_MODERATION_URL = settings.prompt_moderation_url
    CONTENT_CLASSIFICATION_URL = settings.content_classification_url
    MISTRAL_CONNECTOR_URL = settings.mistral_connector_url
    OPENAI_CONNECTOR_URL = settings.openai_connector_url

    @classmethod
    async def process_chat(cls, request: ChatRequest) -> ChatResponse:
        """
        Workflow complet de traitement du chat

        Ã‰tapes:
        1. Extraction du dernier message utilisateur
        2. Classification du contenu (professionnel vs non-professionnel)
        3. ModÃ©ration du prompt (dÃ©tection contenu inappropriÃ©)
        4. Appel au modÃ¨le IA si validation OK
        5. Retour de la rÃ©ponse enrichie avec mÃ©tadonnÃ©es

        Args:
            request: RequÃªte de chat validÃ©e par Pydantic

        Returns:
            RÃ©ponse avec message IA et mÃ©tadonnÃ©es de gouvernance
        """

        # Extraction du dernier message utilisateur
        user_messages = [msg for msg in request.messages if msg.role == "user"]
        last_user_prompt = user_messages[-1].content if user_messages else ""

        # ğŸ” Ã‰TAPE 1: Classification du contenu
        classification = await cls._classify_content(last_user_prompt)

        # ğŸ›¡ï¸ Ã‰TAPE 2: ModÃ©ration du prompt
        moderation = await cls._moderate_prompt(
            last_user_prompt,
            request.strict_mode
        )

        # âŒ Blocage si contenu inappropriÃ© dÃ©tectÃ©
        if not moderation.get("is_appropriate", True):
            return ChatResponse(
                success=False,
                error="Contenu inappropriÃ© dÃ©tectÃ©",
                blocked_reason=moderation.get("reason", "Contenu non conforme dÃ©tectÃ©"),
                moderation_metadata=moderation,
                classification_metadata=classification,
                metadata={
                    "blocked_at_stage": "moderation",
                    "processing_time_seconds": 0
                }
            )

        # ğŸ¤– Ã‰TAPE 3: Appel au modÃ¨le IA
        try:
            ai_response = await cls._call_ai_provider(request)

            # âœ… Retour de la rÃ©ponse enrichie
            return ChatResponse(
                success=True,
                message=ai_response.get("message"),
                moderation_metadata=moderation,
                classification_metadata=classification,
                metadata={
                    "provider": request.provider,
                    "model": request.model,
                    "processing_time_seconds": ai_response.get("processing_time", 0)
                }
            )

        except Exception as e:
            return ChatResponse(
                success=False,
                error=f"Erreur lors de l'appel IA: {str(e)}",
                moderation_metadata=moderation,
                classification_metadata=classification
            )

    @classmethod
    async def _classify_content(cls, text: str) -> Dict:
        """Appelle le service de classification de contenu"""
        async with httpx.AsyncClient(timeout=30.0) as client:
            try:
                response = await client.post(
                    f"{cls.CONTENT_CLASSIFICATION_URL}/api/v1/classify",
                    json={"text": text}
                )

                if response.status_code == 200:
                    return response.json()
                else:
                    # Fallback en cas d'erreur
                    return {"is_professional": True, "confidence": 0.0}

            except Exception as e:
                print(f"âŒ Erreur classification: {e}")
                return {"is_professional": True, "confidence": 0.0}

    @classmethod
    async def _moderate_prompt(cls, prompt: str, strict_mode: bool) -> Dict:
        """Appelle le service de modÃ©ration de prompts"""
        async with httpx.AsyncClient(timeout=30.0) as client:
            try:
                response = await client.post(
                    f"{cls.PROMPT_MODERATION_URL}/api/v1/moderate/prompt",
                    json={
                        "prompt": prompt,
                        "strict_mode": strict_mode
                    }
                )

                if response.status_code == 200:
                    return response.json()
                else:
                    # Fallback: autoriser par dÃ©faut si le service est down
                    return {"is_appropriate": True}

            except Exception as e:
                print(f"âŒ Erreur modÃ©ration: {e}")
                return {"is_appropriate": True}

    @classmethod
    async def _call_ai_provider(cls, request: ChatRequest) -> Dict:
        """Appelle le connecteur IA (Mistral ou OpenAI)"""

        # SÃ©lection du connecteur selon le provider
        if request.provider == "mistral":
            url = f"{cls.MISTRAL_CONNECTOR_URL}/api/v1/mistral/chat"
        elif request.provider == "openai":
            url = f"{cls.OPENAI_CONNECTOR_URL}/api/v1/openai/chat"
        else:
            raise ValueError(f"Provider inconnu: {request.provider}")

        # PrÃ©paration de la requÃªte
        payload = {
            "messages": [msg.dict() for msg in request.messages],
            "model": request.model,
            "temperature": request.temperature,
            "max_tokens": request.max_tokens
        }

        # Ajout de la clÃ© API si fournie
        if request.mistral_api_key:
            payload["api_key"] = request.mistral_api_key
        if request.openai_api_key:
            payload["api_key"] = request.openai_api_key

        # Appel au connecteur
        async with httpx.AsyncClient(timeout=120.0) as client:
            response = await client.post(url, json=payload)
            response.raise_for_status()
            return response.json()
```

**Bonnes Pratiques pour les Services** :
- âœ… MÃ©thodes **publiques** pour les fonctions principales (`process_chat`)
- âœ… MÃ©thodes **privÃ©es** (prÃ©fixe `_`) pour les sous-tÃ¢ches (`_classify_content`)
- âœ… **Asynchrone** (`async`/`await`) pour les appels I/O
- âœ… Gestion des **erreurs** avec try/except
- âœ… **Fallbacks** en cas d'erreur (ex: classification par dÃ©faut)
- âœ… **Logging** pour le debugging
- âŒ **NE PAS** accÃ©der directement Ã  `request.headers` (c'est le rÃ´le du router)

---

#### 3. ğŸ›£ï¸ Routers (Points d'EntrÃ©e API)

**RÃ´le** : Exposer les endpoints HTTP et orchestrer la requÃªte/rÃ©ponse

**ResponsabilitÃ©s** :
- âœ… DÃ©finir les **routes** (endpoints) de l'API
- âœ… DÃ©clarer les **mÃ©thodes HTTP** (GET, POST, PUT, DELETE)
- âœ… GÃ©rer l'**authentification/autorisation** (si nÃ©cessaire)
- âœ… Extraire les paramÃ¨tres (query, path, body, headers)
- âœ… Appeler les **services** pour la logique mÃ©tier
- âœ… GÃ©rer les **codes HTTP** de rÃ©ponse (200, 400, 500, etc.)
- âŒ **NE PAS** contenir de logique mÃ©tier complexe

**Localisation** : `app/routers/[nom].py`

**Pattern** : APIRouter de FastAPI

**Exemple Concret** :

```python
# agents/ai-chat-agent/app/routers/chat.py

from fastapi import APIRouter, HTTPException, Header, Depends
from typing import Optional
from app.models.chat import ChatRequest, ChatResponse
from app.services.chat_service import ChatService

# CrÃ©ation du router
router = APIRouter(
    prefix="/api/v1/chat",
    tags=["Chat"]  # Pour la doc OpenAPI
)

@router.post("/completions", response_model=ChatResponse)
async def chat_completions(
    request: ChatRequest,
    x_api_key: Optional[str] = Header(None)
) -> ChatResponse:
    """
    Endpoint principal de chat avec gouvernance

    FonctionnalitÃ©s:
    - Classification automatique du contenu
    - ModÃ©ration du prompt
    - Appel au modÃ¨le IA (Mistral ou OpenAI)
    - Retour des mÃ©tadonnÃ©es de gouvernance

    Args:
        request: RequÃªte de chat (validÃ©e par Pydantic)
        x_api_key: ClÃ© API optionnelle (header HTTP)

    Returns:
        RÃ©ponse avec message IA et mÃ©tadonnÃ©es

    Raises:
        HTTPException: Si erreur serveur (500)
    """

    try:
        # Appel au service (toute la logique est lÃ -bas)
        response = await ChatService.process_chat(request)
        return response

    except ValueError as e:
        # Erreur de validation (ex: provider inconnu)
        raise HTTPException(
            status_code=400,
            detail=f"RequÃªte invalide: {str(e)}"
        )

    except Exception as e:
        # Erreur serveur
        raise HTTPException(
            status_code=500,
            detail=f"Erreur lors du traitement: {str(e)}"
        )

@router.get("/providers")
async def list_providers():
    """
    Liste des providers IA disponibles

    Returns:
        Liste des providers avec leurs modÃ¨les
    """
    return {
        "providers": [
            {
                "id": "mistral",
                "name": "Mistral AI",
                "models": [
                    "mistral-large-latest",
                    "mistral-small-latest",
                    "mistral-medium-latest"
                ]
            },
            {
                "id": "openai",
                "name": "OpenAI",
                "models": [
                    "gpt-4",
                    "gpt-4-turbo",
                    "gpt-3.5-turbo"
                ]
            }
        ]
    }

@router.get("/models/{provider}")
async def list_models_for_provider(provider: str):
    """
    Liste les modÃ¨les disponibles pour un provider

    Args:
        provider: ID du provider (mistral, openai)

    Returns:
        Liste des modÃ¨les

    Raises:
        HTTPException: Si provider inconnu (404)
    """

    models_map = {
        "mistral": [
            "mistral-large-latest",
            "mistral-small-latest"
        ],
        "openai": [
            "gpt-4",
            "gpt-3.5-turbo"
        ]
    }

    if provider not in models_map:
        raise HTTPException(
            status_code=404,
            detail=f"Provider '{provider}' non trouvÃ©"
        )

    return {
        "provider": provider,
        "models": models_map[provider]
    }

@router.delete("/history/{session_id}")
async def clear_chat_history(
    session_id: str,
    x_api_key: str = Header(...)
):
    """
    Supprime l'historique d'une session

    Args:
        session_id: ID de la session
        x_api_key: ClÃ© API (obligatoire via header)

    Returns:
        Confirmation de suppression
    """

    # Note: En production, vÃ©rifier x_api_key avant de continuer

    # Appel Ã  un service de gestion de sessions (non implÃ©mentÃ© ici)
    # await SessionService.clear_history(session_id)

    return {
        "success": True,
        "message": f"Historique de la session {session_id} supprimÃ©"
    }
```

**Bonnes Pratiques pour les Routers** :
- âœ… Utiliser les **type hints** pour auto-gÃ©nÃ©ration de la doc
- âœ… DÃ©clarer `response_model` pour validation de sortie
- âœ… GÃ©rer les **codes HTTP** appropriÃ©s (200, 400, 404, 500)
- âœ… Utiliser `HTTPException` pour les erreurs
- âœ… Documenter avec **docstrings** (apparaÃ®t dans OpenAPI)
- âœ… Grouper par **tags** pour la doc
- âŒ **NE PAS** mettre de logique mÃ©tier (Ã§a va dans le service)

---

### Flux de RequÃªte Complet

Voici le chemin d'une requÃªte HTTP Ã  travers les trois couches :

```mermaid
sequenceDiagram
    participant Client as ğŸŒ Client HTTP
    participant Router as ğŸ›£ï¸ Router
    participant Model as ğŸ“¦ Pydantic Model
    participant Service as ğŸ§  Service
    participant External as â˜ï¸ Services Externes

    Client->>Router: POST /api/v1/chat/completions<br/>{messages: [...]}

    Note over Router: Extraction du body JSON

    Router->>Model: Validation avec ChatRequest

    alt DonnÃ©es invalides
        Model-->>Router: ValidationError
        Router-->>Client: 400 Bad Request<br/>{detail: "..."}
    else DonnÃ©es valides
        Model-->>Router: ChatRequest validÃ©

        Router->>Service: process_chat(request)

        Note over Service: Ã‰TAPE 1: Classification
        Service->>External: POST /api/v1/classify
        External-->>Service: {is_professional: true}

        Note over Service: Ã‰TAPE 2: ModÃ©ration
        Service->>External: POST /api/v1/moderate
        External-->>Service: {is_appropriate: true}

        Note over Service: Ã‰TAPE 3: Appel IA
        Service->>External: POST /api/v1/mistral/chat
        External-->>Service: {message: "..."}

        Note over Service: AgrÃ©gation mÃ©tadonnÃ©es

        Service-->>Router: ChatResponse

        Router->>Model: SÃ©rialisation ChatResponse
        Model-->>Router: JSON validÃ©

        Router-->>Client: 200 OK<br/>{success: true, message: "..."}
    end
```

---

### Tableau RÃ©capitulatif

| Couche | Localisation | ResponsabilitÃ© Principale | DÃ©pendances |
|--------|-------------|---------------------------|-------------|
| **Models** | `app/models/` | DÃ©finir structures de donnÃ©es et validation | Pydantic |
| **Services** | `app/services/` | Logique mÃ©tier et orchestration | httpx, Models, Config |
| **Routers** | `app/routers/` | Endpoints HTTP et gestion requÃªtes/rÃ©ponses | FastAPI, Models, Services |

---

### Exemple de Dossier Complet

```
agents/ai-chat-agent/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ chat.py              # âœ… ChatRequest, ChatResponse, ChatMessage
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ chat_service.py      # âœ… ChatService.process_chat()
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ chat.py              # âœ… @router.post("/completions")
â”‚   â”œâ”€â”€ config.py                # âš™ï¸ Settings et URLs
â”‚   â””â”€â”€ main.py                  # ğŸš€ FastAPI app + include_router()
```

---

### Avantages de cette Architecture

âœ… **SÃ©paration des responsabilitÃ©s** : Chaque couche a un rÃ´le clair

âœ… **TestabilitÃ©** : Services et Models peuvent Ãªtre testÃ©s indÃ©pendamment

âœ… **MaintenabilitÃ©** : Facile de modifier la logique mÃ©tier sans toucher aux routes

âœ… **RÃ©utilisabilitÃ©** : Les services peuvent Ãªtre appelÃ©s depuis plusieurs routers

âœ… **Documentation auto-gÃ©nÃ©rÃ©e** : OpenAPI/Swagger crÃ©Ã© automatiquement

âœ… **Validation automatique** : Pydantic valide les donnÃ©es Ã  l'entrÃ©e/sortie

âœ… **Type safety** : DÃ©tection d'erreurs avec mypy et auto-complÃ©tion IDE

---

## Architecture Globale

```mermaid
graph TB
    subgraph "Frontend (Angular - Port 4200)"
        UI[Interface Utilisateur<br/>Catalogue & Pages Agents]
    end

    subgraph "Agents Orchestrateurs (Ports 8009-8019)"
        A1[AI Chat Agent<br/>:8012]
        A2[Web Monitoring<br/>:8017]
        A3[Document Analyzer<br/>:8009]
        A4[Contract Analysis<br/>:8018]
        A5[POD Analyzer<br/>:8019]
        A6[Appointment Scheduler<br/>:8010]
        A7[Dolibarr Stats<br/>:8016]
    end

    subgraph "Connecteurs Centraux (Ports 8005-8015)"
        C1[Mistral Connector<br/>:8005]
        C2[OpenAI Connector<br/>:8006]
        C3[Dolibarr Connector<br/>:8015]
    end

    subgraph "Tools Utilitaires (Ports 8001-8011, 8020)"
        T1[Web Search<br/>:8002]
        T2[Document Extractor<br/>:8008]
        T3[PDF CRUD<br/>:8003]
        T4[Word CRUD<br/>:8001]
        T5[Excel CRUD<br/>:8004]
        T6[PPTX CRUD<br/>:8011]
        T7[EML Parser<br/>:8020]
    end

    subgraph "Tools de Gouvernance (Ports 8013-8014)"
        G1[Prompt Moderation<br/>:8013]
        G2[Content Classification<br/>:8014]
    end

    subgraph "Services Externes"
        EX1[Mistral AI API]
        EX2[OpenAI API]
        EX3[Dolibarr CRM]
        EX4[Moteurs de recherche]
    end

    UI --> A1
    UI --> A2
    UI --> A3
    UI --> A4
    UI --> A5

    A1 --> G1
    A1 --> G2
    A1 --> C1
    A1 --> C2

    A2 --> T1
    A2 --> C1

    A3 --> T2
    A3 --> T4
    A3 --> C1

    A4 --> T2
    A4 --> T4
    A4 --> C1
    A4 --> C2

    A5 --> T7
    A5 --> T3
    A5 --> C1
    A5 --> C2

    A6 --> T1
    A6 --> T6
    A6 --> C1

    A7 --> C3
    A7 --> C1

    C1 --> EX1
    C2 --> EX2
    C3 --> EX3
    T1 --> EX4

    style UI fill:#e1f5ff
    style A1 fill:#fff4e6
    style A2 fill:#fff4e6
    style A3 fill:#fff4e6
    style A4 fill:#fff4e6
    style A5 fill:#fff4e6
    style C1 fill:#f3e5f5
    style C2 fill:#f3e5f5
    style C3 fill:#f3e5f5
    style T1 fill:#e8f5e9
    style T2 fill:#e8f5e9
    style G1 fill:#ffebee
    style G2 fill:#ffebee
```

### LÃ©gende des Couleurs

- ğŸ”µ **Bleu**: Interface utilisateur (Angular)
- ğŸŸ  **Orange**: Agents orchestrateurs (logique mÃ©tier)
- ğŸŸ£ **Violet**: Connecteurs centraux (accÃ¨s APIs externes)
- ğŸŸ¢ **Vert**: Tools utilitaires (fonctions spÃ©cialisÃ©es)
- ğŸ”´ **Rouge**: Tools de gouvernance (sÃ©curitÃ©/modÃ©ration)

---

## Les Agents Orchestrateurs

### DÃ©finition

Un **agent** est un microservice qui:
- âœ… Coordonne plusieurs outils et connecteurs
- âœ… ImplÃ©mente une logique mÃ©tier complexe
- âœ… Expose une API REST publique utilisÃ©e par le frontend
- âœ… GÃ¨re les workflows multi-Ã©tapes
- âœ… Ne fait pas de calcul direct, dÃ©lÃ¨gue aux tools

### Liste des Agents

| Agent | Port | Description | Outils UtilisÃ©s |
|-------|------|-------------|-----------------|
| **AI Chat Agent** | 8012 | Chat IA avec gouvernance | Prompt Moderation, Content Classification, Mistral/OpenAI |
| **Web Monitoring Agent** | 8017 | Veille technologique automatisÃ©e | Web Search, Mistral/OpenAI |
| **Document Analyzer** | 8009 | Analyse de documents (appels d'offre) | Document Extractor, Word CRUD, Mistral |
| **Appointment Scheduler** | 8010 | PrÃ©paration rendez-vous commerciaux | Web Search, PPTX CRUD, Mistral |
| **Contract Analysis Agent** | 8018 | Analyse juridique de contrats | Document Extractor, Word CRUD, Mistral/OpenAI |
| **Dolibarr Stats Agent** | 8016 | Analyse CRM avec recommandations | Dolibarr Connector, Mistral |
| **Email POD Analyzer** | 8019 | CorrÃ©lation POD/BDC dans emails | EML Parser, PDF CRUD, Mistral/OpenAI |

### Structure d'un Agent

```
agents/[agent-name]/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                    # ğŸš€ Point d'entrÃ©e FastAPI
â”‚   â”œâ”€â”€ config.py                  # âš™ï¸ Configuration (URLs des dÃ©pendances)
â”‚   â”œâ”€â”€ routers/                   # ğŸ›£ï¸ Endpoints API
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ [endpoint].py          # Ex: chat.py, analyze.py
â”‚   â”œâ”€â”€ services/                  # ğŸ§  Logique d'orchestration
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ [service].py           # Ex: chat_service.py
â”‚   â”œâ”€â”€ models/                    # ğŸ“¦ ModÃ¨les Pydantic
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ [models].py            # Schemas request/response
â”‚   â””â”€â”€ middleware/                # ğŸ”’ Middleware (auth, etc.)
â”‚       â””â”€â”€ auth.py
â”œâ”€â”€ requirements.txt               # ğŸ“‹ DÃ©pendances Python
â”œâ”€â”€ Dockerfile                     # ğŸ³ Image Docker
â””â”€â”€ README.md                      # ğŸ“– Documentation
```

### Exemple de Configuration

**Fichier**: `agents/ai-chat-agent/app/config.py`

```python
import os
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    # Informations de base
    app_name: str = "AI Chat Agent"
    version: str = "1.0.0"

    # URLs des services dÃ©pendants
    prompt_moderation_url: str = os.getenv(
        "PROMPT_MODERATION_URL",
        "http://prompt-moderation-tool:8000"
    )
    content_classification_url: str = os.getenv(
        "CONTENT_CLASSIFICATION_URL",
        "http://content-classification-tool:8000"
    )
    mistral_connector_url: str = os.getenv(
        "MISTRAL_CONNECTOR_URL",
        "http://mistral-connector:8000"
    )
    openai_connector_url: str = os.getenv(
        "OPENAI_CONNECTOR_URL",
        "http://openai-connector:8000"
    )

    class Config:
        env_file = ".env"

settings = Settings()
```

### Exemple de Point d'EntrÃ©e

**Fichier**: `agents/ai-chat-agent/app/main.py`

```python
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from app.config import settings
from app.routers import chat

# Initialisation de l'application FastAPI
app = FastAPI(
    title=settings.app_name,
    version=settings.version,
    description="Agent de chat IA avec gouvernance"
)

# Configuration CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # En production: spÃ©cifier les domaines
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Inclusion des routers
app.include_router(chat.router, tags=["Chat"])

# Health check (utilisÃ© par Docker)
@app.get("/health")
async def health():
    return {
        "status": "healthy",
        "service": settings.app_name,
        "version": settings.version
    }

# Informations sur le service
@app.get("/")
async def root():
    return {
        "service": settings.app_name,
        "version": settings.version,
        "endpoints": [
            "/api/v1/chat/completions",
            "/api/v1/chat/providers",
            "/health"
        ]
    }
```

### Exemple de Service d'Orchestration

**Fichier**: `agents/ai-chat-agent/app/services/chat_service.py`

```python
import httpx
from typing import List, Dict
from app.config import settings
from app.models.chat import ChatRequest, ChatResponse, ChatMessage

class ChatService:
    """Service d'orchestration pour le chat IA avec gouvernance"""

    PROMPT_MODERATION_URL = settings.prompt_moderation_url
    CONTENT_CLASSIFICATION_URL = settings.content_classification_url
    MISTRAL_CONNECTOR_URL = settings.mistral_connector_url
    OPENAI_CONNECTOR_URL = settings.openai_connector_url

    @classmethod
    async def process_chat(cls, request: ChatRequest) -> ChatResponse:
        """
        Workflow complet de traitement du chat:
        1. Classification du contenu
        2. ModÃ©ration du prompt
        3. Appel au modÃ¨le IA
        """

        # Extraction du dernier message utilisateur
        user_messages = [msg for msg in request.messages if msg.role == "user"]
        last_user_prompt = user_messages[-1].content if user_messages else ""

        # ğŸ” Ã‰TAPE 1: Classification du contenu
        classification = await cls._classify_content(last_user_prompt)

        # ğŸ›¡ï¸ Ã‰TAPE 2: ModÃ©ration du prompt
        moderation = await cls._moderate_prompt(
            last_user_prompt,
            request.strict_mode
        )

        # âŒ Blocage si contenu inappropriÃ© dÃ©tectÃ©
        if not moderation.get("is_appropriate", True):
            return ChatResponse(
                success=False,
                error="Contenu inappropriÃ© dÃ©tectÃ©",
                blocked_reason=moderation.get("reason", ""),
                moderation_metadata=moderation,
                classification_metadata=classification,
                metadata={
                    "blocked_at_stage": "moderation",
                    "processing_time_seconds": 0
                }
            )

        # ğŸ¤– Ã‰TAPE 3: Appel au modÃ¨le IA
        ai_response = await cls._call_ai_provider(request)

        # âœ… Retour de la rÃ©ponse enrichie
        return ChatResponse(
            success=True,
            message=ai_response.get("message"),
            moderation_metadata=moderation,
            classification_metadata=classification,
            metadata={
                "provider": request.provider,
                "model": request.model,
                "processing_time_seconds": ai_response.get("processing_time", 0)
            }
        )

    @classmethod
    async def _classify_content(cls, text: str) -> Dict:
        """Appelle le service de classification de contenu"""
        async with httpx.AsyncClient(timeout=30.0) as client:
            try:
                response = await client.post(
                    f"{cls.CONTENT_CLASSIFICATION_URL}/api/v1/classify",
                    json={"text": text}
                )

                if response.status_code == 200:
                    return response.json()
                else:
                    return {"is_professional": True, "confidence": 0.0}

            except Exception as e:
                print(f"âŒ Erreur classification: {e}")
                return {"is_professional": True, "confidence": 0.0}

    @classmethod
    async def _moderate_prompt(cls, prompt: str, strict_mode: bool) -> Dict:
        """Appelle le service de modÃ©ration de prompts"""
        async with httpx.AsyncClient(timeout=30.0) as client:
            try:
                response = await client.post(
                    f"{cls.PROMPT_MODERATION_URL}/api/v1/moderate/prompt",
                    json={
                        "prompt": prompt,
                        "strict_mode": strict_mode
                    }
                )

                if response.status_code == 200:
                    return response.json()
                else:
                    return {"is_appropriate": True}

            except Exception as e:
                print(f"âŒ Erreur modÃ©ration: {e}")
                return {"is_appropriate": True}

    @classmethod
    async def _call_ai_provider(cls, request: ChatRequest) -> Dict:
        """Appelle le connecteur IA (Mistral ou OpenAI)"""

        # SÃ©lection du connecteur selon le provider
        if request.provider == "mistral":
            url = f"{cls.MISTRAL_CONNECTOR_URL}/api/v1/mistral/chat"
        elif request.provider == "openai":
            url = f"{cls.OPENAI_CONNECTOR_URL}/api/v1/openai/chat"
        else:
            raise ValueError(f"Provider inconnu: {request.provider}")

        # PrÃ©paration de la requÃªte
        payload = {
            "messages": [msg.dict() for msg in request.messages],
            "model": request.model,
            "temperature": request.temperature,
            "max_tokens": request.max_tokens
        }

        # Ajout de la clÃ© API si fournie
        if request.mistral_api_key:
            payload["api_key"] = request.mistral_api_key
        if request.openai_api_key:
            payload["api_key"] = request.openai_api_key

        # Appel au connecteur
        async with httpx.AsyncClient(timeout=120.0) as client:
            response = await client.post(url, json=payload)
            response.raise_for_status()
            return response.json()
```

### Exemple de Router

**Fichier**: `agents/ai-chat-agent/app/routers/chat.py`

```python
from fastapi import APIRouter, HTTPException
from app.models.chat import ChatRequest, ChatResponse
from app.services.chat_service import ChatService

router = APIRouter(prefix="/api/v1/chat")

@router.post("/completions", response_model=ChatResponse)
async def chat_completions(request: ChatRequest) -> ChatResponse:
    """
    Endpoint principal de chat avec gouvernance

    - Classification automatique du contenu
    - ModÃ©ration du prompt
    - Appel au modÃ¨le IA
    """
    try:
        response = await ChatService.process_chat(request)
        return response

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Erreur lors du traitement: {str(e)}"
        )

@router.get("/providers")
async def list_providers():
    """Liste des providers IA disponibles"""
    return {
        "providers": [
            {
                "id": "mistral",
                "name": "Mistral AI",
                "models": ["mistral-large-latest", "mistral-small-latest"]
            },
            {
                "id": "openai",
                "name": "OpenAI",
                "models": ["gpt-4", "gpt-3.5-turbo"]
            }
        ]
    }
```

### Workflow d'un Agent

```mermaid
sequenceDiagram
    participant UI as Frontend (Angular)
    participant Agent as Agent Orchestrateur
    participant Tool1 as Tool 1
    participant Tool2 as Tool 2
    participant Connector as Connecteur IA

    UI->>Agent: POST /api/v1/endpoint (requÃªte)

    Note over Agent: Validation Pydantic

    Agent->>Tool1: POST /api/v1/tool1/action
    Tool1-->>Agent: RÃ©ponse Tool1

    Note over Agent: Traitement intermÃ©diaire

    Agent->>Tool2: POST /api/v1/tool2/action
    Tool2-->>Agent: RÃ©ponse Tool2

    Note over Agent: AgrÃ©gation des donnÃ©es

    Agent->>Connector: POST /api/v1/chat
    Connector->>Connector: Appel API externe
    Connector-->>Agent: RÃ©ponse IA

    Note over Agent: Formatage de la rÃ©ponse

    Agent-->>UI: ChatResponse (JSON)
```

---

## Les Tools (Outils)

### DÃ©finition

Un **tool** est un microservice spÃ©cialisÃ© qui:
- âœ… Fournit **une seule fonctionnalitÃ©** bien dÃ©finie
- âœ… Peut Ãªtre utilisÃ© par **plusieurs agents**
- âœ… N'appelle pas d'autres tools (sauf exceptions)
- âœ… Est **stateless** (sans Ã©tat partagÃ©)
- âœ… Expose une API REST simple

### CatÃ©gories de Tools

#### 1. Tools Utilitaires (Fonctions Techniques)

| Tool | Port | Fonction | Technologie |
|------|------|----------|-------------|
| **Web Search** | 8002 | Recherche web multi-moteurs | DuckDuckGo, BeautifulSoup |
| **Document Extractor** | 8008 | Extraction texte de documents | PyPDF2, python-docx, openpyxl |
| **PDF CRUD** | 8003 | Manipulation de fichiers PDF | ReportLab, PyPDF2 |
| **Word CRUD** | 8001 | Manipulation de fichiers Word | python-docx |
| **Excel CRUD** | 8004 | Manipulation de fichiers Excel | openpyxl |
| **PPTX CRUD** | 8011 | Manipulation de fichiers PowerPoint | python-pptx |
| **File Upload** | 8007 | Gestion d'upload de fichiers | FastAPI UploadFile |
| **EML Parser** | 8020 | Parsing d'emails (.eml) | email (stdlib) |

#### 2. Tools de Gouvernance (SÃ©curitÃ© & ConformitÃ©)

| Tool | Port | Fonction | Technologie |
|------|------|----------|-------------|
| **Prompt Moderation** | 8013 | DÃ©tection contenu inappropriÃ© | Mistral Moderation API |
| **Content Classification** | 8014 | Classification professionnel/non-professionnel | Mistral AI |

### Structure d'un Tool

```
tools/[tool-name]/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                    # ğŸš€ Point d'entrÃ©e FastAPI
â”‚   â”œâ”€â”€ config.py                  # âš™ï¸ Configuration minimale
â”‚   â”œâ”€â”€ routers/                   # ğŸ›£ï¸ Endpoints API
â”‚   â”‚   â””â”€â”€ [operation].py         # Ex: search.py, extract.py
â”‚   â”œâ”€â”€ services/                  # ğŸ§  Logique mÃ©tier
â”‚   â”‚   â””â”€â”€ [service].py           # Ex: search_service.py
â”‚   â””â”€â”€ models/                    # ğŸ“¦ ModÃ¨les Pydantic
â”‚       â””â”€â”€ [models].py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md
```

### Exemple de Tool: Web Search

#### Configuration

**Fichier**: `tools/web-search-tool/app/config.py`

```python
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    app_name: str = "Web Search Tool"
    version: str = "1.0.0"

    # Pas de dÃ©pendances externes (tool autonome)
    default_search_engine: str = "duckduckgo"
    max_results: int = 10
    timeout_seconds: int = 30

settings = Settings()
```

#### Service

**Fichier**: `tools/web-search-tool/app/services/search_service.py`

```python
import httpx
from bs4 import BeautifulSoup
from typing import List, Dict
from app.models.search import SearchRequest, SearchResult

class SearchService:
    """Service de recherche web multi-moteurs"""

    @staticmethod
    async def search(request: SearchRequest) -> List[SearchResult]:
        """
        Effectue une recherche web

        Supporte: DuckDuckGo, Google, Bing
        """

        if request.engine == "duckduckgo":
            return await SearchService._search_duckduckgo(
                request.query,
                request.max_results
            )

        elif request.engine == "google":
            return await SearchService._search_google(
                request.query,
                request.max_results
            )

        elif request.engine == "bing":
            return await SearchService._search_bing(
                request.query,
                request.max_results
            )

        else:
            raise ValueError(f"Moteur inconnu: {request.engine}")

    @staticmethod
    async def _search_duckduckgo(query: str, max_results: int) -> List[SearchResult]:
        """Recherche sur DuckDuckGo"""

        url = "https://html.duckduckgo.com/html/"
        params = {"q": query}

        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(url, data=params)
            response.raise_for_status()

            soup = BeautifulSoup(response.text, "html.parser")
            results = []

            for result in soup.find_all("div", class_="result")[:max_results]:
                title_elem = result.find("a", class_="result__a")
                snippet_elem = result.find("a", class_="result__snippet")

                if title_elem:
                    results.append(SearchResult(
                        title=title_elem.get_text(strip=True),
                        url=title_elem.get("href", ""),
                        snippet=snippet_elem.get_text(strip=True) if snippet_elem else ""
                    ))

            return results

    @staticmethod
    async def extract_page_content(url: str) -> Dict:
        """Extrait le contenu d'une page web"""

        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.get(url)
            response.raise_for_status()

            soup = BeautifulSoup(response.text, "html.parser")

            # Suppression des scripts et styles
            for tag in soup(["script", "style"]):
                tag.decompose()

            # Extraction du texte
            text = soup.get_text(separator="\n", strip=True)

            return {
                "url": url,
                "title": soup.title.string if soup.title else "",
                "content": text,
                "links": [a.get("href") for a in soup.find_all("a", href=True)]
            }
```

#### Router

**Fichier**: `tools/web-search-tool/app/routers/search.py`

```python
from fastapi import APIRouter, HTTPException
from app.models.search import SearchRequest, SearchResponse, PageContentRequest
from app.services.search_service import SearchService

router = APIRouter(prefix="/api/v1/search")

@router.post("/", response_model=SearchResponse)
async def search_web(request: SearchRequest) -> SearchResponse:
    """Effectue une recherche web"""
    try:
        results = await SearchService.search(request)

        return SearchResponse(
            success=True,
            query=request.query,
            engine=request.engine,
            results=results,
            count=len(results)
        )

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Erreur de recherche: {str(e)}"
        )

@router.post("/extract")
async def extract_content(request: PageContentRequest):
    """Extrait le contenu d'une page web"""
    try:
        content = await SearchService.extract_page_content(request.url)
        return content

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Erreur d'extraction: {str(e)}"
        )
```

#### ModÃ¨les

**Fichier**: `tools/web-search-tool/app/models/search.py`

```python
from pydantic import BaseModel, Field, HttpUrl
from typing import List, Optional
from enum import Enum

class SearchEngine(str, Enum):
    """Moteurs de recherche supportÃ©s"""
    DUCKDUCKGO = "duckduckgo"
    GOOGLE = "google"
    BING = "bing"

class SearchRequest(BaseModel):
    """RequÃªte de recherche"""
    query: str = Field(..., min_length=1, description="RequÃªte de recherche")
    engine: SearchEngine = Field(default=SearchEngine.DUCKDUCKGO)
    max_results: int = Field(default=10, ge=1, le=50)

class SearchResult(BaseModel):
    """RÃ©sultat de recherche"""
    title: str
    url: str
    snippet: Optional[str] = None

class SearchResponse(BaseModel):
    """RÃ©ponse de recherche"""
    success: bool
    query: str
    engine: str
    results: List[SearchResult]
    count: int

class PageContentRequest(BaseModel):
    """RequÃªte d'extraction de contenu"""
    url: HttpUrl
```

---

## Les Connecteurs Centraux

### DÃ©finition

Un **connecteur** est un service qui:
- âœ… Encapsule l'accÃ¨s Ã  une **API externe**
- âœ… GÃ¨re les **clÃ©s API** et l'**authentification**
- âœ… Fournit une **interface unifiÃ©e** pour tous les agents
- âœ… GÃ¨re les **erreurs** et les **retry**

### Liste des Connecteurs

| Connecteur | Port | API Externe | FonctionnalitÃ©s |
|-----------|------|-------------|-----------------|
| **Mistral Connector** | 8005 | Mistral AI | Chat, Embeddings, ModÃ©ration |
| **OpenAI Connector** | 8006 | OpenAI | Chat, Embeddings, ModÃ¨les |
| **Dolibarr Connector** | 8015 | Dolibarr CRM | Stats, Clients, Projets |

### Exemple: Mistral Connector

**Fichier**: `core/mistral-connector/app/routers/chat.py`

```python
from fastapi import APIRouter, HTTPException
import httpx
from app.config import settings
from app.models.chat import MistralChatRequest, MistralChatResponse

router = APIRouter(prefix="/api/v1/mistral")

@router.post("/chat", response_model=MistralChatResponse)
async def chat_completion(request: MistralChatRequest):
    """
    Appel Ã  l'API Mistral Chat

    Encapsule l'authentification et la gestion d'erreurs
    """

    # Utilisation de la clÃ© API fournie ou celle par dÃ©faut
    api_key = request.api_key or settings.mistral_api_key

    if not api_key:
        raise HTTPException(
            status_code=401,
            detail="ClÃ© API Mistral manquante"
        )

    # PrÃ©paration de la requÃªte
    payload = {
        "model": request.model,
        "messages": [msg.dict() for msg in request.messages],
        "temperature": request.temperature,
        "max_tokens": request.max_tokens
    }

    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }

    # Appel Ã  l'API Mistral
    async with httpx.AsyncClient(timeout=120.0) as client:
        try:
            response = await client.post(
                "https://api.mistral.ai/v1/chat/completions",
                json=payload,
                headers=headers
            )
            response.raise_for_status()

            data = response.json()

            return MistralChatResponse(
                success=True,
                message=data["choices"][0]["message"]["content"],
                model=data["model"],
                usage=data.get("usage", {}),
                metadata={
                    "finish_reason": data["choices"][0]["finish_reason"]
                }
            )

        except httpx.HTTPStatusError as e:
            raise HTTPException(
                status_code=e.response.status_code,
                detail=f"Erreur API Mistral: {e.response.text}"
            )

        except Exception as e:
            raise HTTPException(
                status_code=500,
                detail=f"Erreur interne: {str(e)}"
            )

@router.get("/models")
async def list_models():
    """Liste les modÃ¨les Mistral disponibles"""

    api_key = settings.mistral_api_key

    if not api_key:
        raise HTTPException(
            status_code=401,
            detail="ClÃ© API Mistral manquante"
        )

    async with httpx.AsyncClient(timeout=30.0) as client:
        response = await client.get(
            "https://api.mistral.ai/v1/models",
            headers={"Authorization": f"Bearer {api_key}"}
        )
        response.raise_for_status()
        return response.json()
```

---

## Les Briques Graphiques (UI)

### Architecture Frontend

```
ui/frontend/src/app/
â”œâ”€â”€ pages/                          # Pages des agents
â”‚   â”œâ”€â”€ agents-catalog/             # ğŸ  Catalogue central
â”‚   â”‚   â”œâ”€â”€ agents-catalog.component.ts
â”‚   â”‚   â””â”€â”€ agents-catalog.component.html
â”‚   â”œâ”€â”€ ai-chat/                    # ğŸ’¬ Page AI Chat
â”‚   â”‚   â”œâ”€â”€ ai-chat.component.ts
â”‚   â”‚   â”œâ”€â”€ ai-chat.component.html
â”‚   â”‚   â””â”€â”€ chat-config-dialog/     # Configuration
â”‚   â”œâ”€â”€ web-monitoring-agent/       # ğŸ” Veille web
â”‚   â”œâ”€â”€ document-analyzer/          # ğŸ“„ Analyse documents
â”‚   â”œâ”€â”€ contract-analysis/          # âš–ï¸ Analyse contrats
â”‚   â””â”€â”€ pod-analyzer/               # ğŸ“§ Analyse POD
â”œâ”€â”€ services/                       # Services Angular
â”‚   â””â”€â”€ api.service.ts
â”œâ”€â”€ models/                         # ModÃ¨les TypeScript
â”‚   â””â”€â”€ agent.model.ts
â””â”€â”€ shared/                         # Composants partagÃ©s
    â”œâ”€â”€ header/
    â””â”€â”€ loader/
```

### Configuration des Endpoints

**Fichier**: `ui/frontend/src/environments/environment.ts`

```typescript
export const environment = {
  production: false,

  api: {
    // Tools
    wordCrud: 'http://localhost:8001',
    webSearch: 'http://localhost:8002',
    pdfCrud: 'http://localhost:8003',
    excelCrud: 'http://localhost:8004',
    documentExtractor: 'http://localhost:8008',
    pptxCrud: 'http://localhost:8011',

    // Connecteurs
    mistralConnector: 'http://localhost:8005',
    openaiConnector: 'http://localhost:8006',
    dolibarrConnector: 'http://localhost:8015',

    // Agents
    aiChat: 'http://localhost:8012',
    promptModeration: 'http://localhost:8013',
    contentClassification: 'http://localhost:8014',
    webMonitoring: 'http://localhost:8017',
    contractAnalysis: 'http://localhost:8018',
    podAnalyzer: 'http://localhost:8019',
    documentAnalyzer: 'http://localhost:8009',
    appointmentScheduler: 'http://localhost:8010',
    dolibarrStats: 'http://localhost:8016'
  }
};
```

### Catalogue des Agents

**Fichier**: `ui/frontend/src/app/pages/agents-catalog/agents-catalog.component.ts`

```typescript
import { Component, OnInit } from '@angular/core';
import { Router } from '@angular/router';

export interface Agent {
  id: string;
  name: string;
  description: string;
  icon: string;
  route: string;
  hasConfig: boolean;
  status: 'active' | 'beta' | 'coming-soon';
}

@Component({
  selector: 'app-agents-catalog',
  templateUrl: './agents-catalog.component.html',
  styleUrls: ['./agents-catalog.component.scss']
})
export class AgentsCatalogComponent implements OnInit {

  agents: Agent[] = [
    {
      id: 'ai-chat',
      name: 'Assistant IA Professionnel',
      description: 'Chat IA avec gouvernance et modÃ©ration de contenu',
      icon: 'chat',
      route: '/ai-chat',
      hasConfig: true,
      status: 'active'
    },
    {
      id: 'web-monitoring',
      name: 'Veille Technologique',
      description: 'Surveillance et synthÃ¨se d\'actualitÃ©s web',
      icon: 'search',
      route: '/web-monitoring',
      hasConfig: true,
      status: 'active'
    },
    {
      id: 'document-analyzer',
      name: 'Analyse de Documents',
      description: 'Analyse d\'appels d\'offre et cahiers des charges',
      icon: 'description',
      route: '/document-analyzer',
      hasConfig: false,
      status: 'active'
    },
    {
      id: 'contract-analysis',
      name: 'Analyse de Contrats',
      description: 'Analyse juridique de contrats avec extraction de clauses',
      icon: 'gavel',
      route: '/contract-analysis',
      hasConfig: false,
      status: 'active'
    },
    {
      id: 'pod-analyzer',
      name: 'Analyseur POD/BDC',
      description: 'CorrÃ©lation automatique entre POD et bons de commande',
      icon: 'email',
      route: '/pod-analyzer',
      hasConfig: true,
      status: 'active'
    },
    {
      id: 'appointment-scheduler',
      name: 'PrÃ©parateur de Rendez-vous',
      description: 'PrÃ©paration de rendez-vous commerciaux avec recherche',
      icon: 'calendar_today',
      route: '/appointment-scheduler',
      hasConfig: false,
      status: 'beta'
    },
    {
      id: 'dolibarr-stats',
      name: 'Analyse CRM Dolibarr',
      description: 'Statistiques et recommandations depuis Dolibarr',
      icon: 'analytics',
      route: '/dolibarr-stats',
      hasConfig: false,
      status: 'active'
    }
  ];

  constructor(private router: Router) {}

  ngOnInit(): void {
    // Initialisation
  }

  navigateToAgent(agent: Agent): void {
    this.router.navigate([agent.route]);
  }

  openConfig(agent: Agent, event: Event): void {
    event.stopPropagation();
    this.router.navigate([agent.route], { queryParams: { config: true } });
  }
}
```

### Exemple de Composant Agent: AI Chat

**Fichier**: `ui/frontend/src/app/pages/ai-chat/ai-chat.component.ts`

```typescript
import { Component, OnInit } from '@angular/core';
import { HttpClient } from '@angular/common/http';
import { firstValueFrom, timeout } from 'rxjs';
import { environment } from '../../../environments/environment';

export interface ChatMessage {
  role: 'user' | 'assistant' | 'system';
  content: string;
  timestamp?: Date;
}

export interface ChatRequest {
  messages: ChatMessage[];
  provider: 'mistral' | 'openai';
  model?: string;
  temperature?: number;
  max_tokens?: number;
  strict_mode?: boolean;
  mistral_api_key?: string;
  openai_api_key?: string;
}

export interface ChatResponse {
  success: boolean;
  message?: string;
  error?: string;
  blocked_reason?: string;
  moderation_metadata?: any;
  classification_metadata?: any;
  metadata?: any;
}

@Component({
  selector: 'app-ai-chat',
  templateUrl: './ai-chat.component.html',
  styleUrls: ['./ai-chat.component.scss']
})
export class AiChatComponent implements OnInit {

  // Messages du chat
  messages: ChatMessage[] = [];
  currentMessage: string = '';

  // Configuration
  provider: 'mistral' | 'openai' = 'mistral';
  model: string = 'mistral-large-latest';
  temperature: number = 0.7;
  strictMode: boolean = false;
  mistralApiKey?: string;
  openaiApiKey?: string;

  // Ã‰tat
  isLoading: boolean = false;
  error?: string;

  constructor(private http: HttpClient) {}

  ngOnInit(): void {
    // Chargement de la configuration depuis localStorage
    this.loadConfiguration();

    // Message de bienvenue
    this.messages.push({
      role: 'assistant',
      content: 'Bonjour ! Je suis votre assistant IA professionnel. Comment puis-je vous aider ?',
      timestamp: new Date()
    });
  }

  async sendMessage(): Promise<void> {
    if (!this.currentMessage.trim() || this.isLoading) {
      return;
    }

    // Ajout du message utilisateur
    const userMessage: ChatMessage = {
      role: 'user',
      content: this.currentMessage,
      timestamp: new Date()
    };

    this.messages.push(userMessage);
    const userInput = this.currentMessage;
    this.currentMessage = '';
    this.isLoading = true;
    this.error = undefined;

    try {
      // PrÃ©paration de la requÃªte
      const requestMessages = this.messages.map(m => ({
        role: m.role,
        content: m.content
      }));

      const request: ChatRequest = {
        messages: requestMessages,
        provider: this.provider,
        model: this.model,
        temperature: this.temperature,
        strict_mode: this.strictMode
      };

      // Ajout des clÃ©s API si fournies
      if (this.mistralApiKey) {
        request.mistral_api_key = this.mistralApiKey;
      }
      if (this.openaiApiKey) {
        request.openai_api_key = this.openaiApiKey;
      }

      // Appel Ã  l'API
      const response = await firstValueFrom(
        this.http.post<ChatResponse>(
          `${environment.api.aiChat}/api/v1/chat/completions`,
          request
        ).pipe(timeout(180000)) // 3 minutes timeout
      );

      // Traitement de la rÃ©ponse
      if (response.success && response.message) {
        this.messages.push({
          role: 'assistant',
          content: response.message,
          timestamp: new Date()
        });
      } else if (response.blocked_reason) {
        // Contenu bloquÃ© par la modÃ©ration
        this.messages.push({
          role: 'assistant',
          content: `âš ï¸ ${response.blocked_reason}`,
          timestamp: new Date()
        });
      } else {
        throw new Error(response.error || 'Erreur inconnue');
      }

    } catch (err: any) {
      this.error = err.message || 'Erreur de communication avec le serveur';
      console.error('Erreur chat:', err);

      // Message d'erreur dans le chat
      this.messages.push({
        role: 'assistant',
        content: `âŒ Erreur: ${this.error}`,
        timestamp: new Date()
      });

    } finally {
      this.isLoading = false;
    }
  }

  loadConfiguration(): void {
    // Chargement depuis localStorage
    const config = localStorage.getItem('aiChatConfig');

    if (config) {
      const parsed = JSON.parse(config);
      this.provider = parsed.provider || 'mistral';
      this.model = parsed.model || 'mistral-large-latest';
      this.temperature = parsed.temperature || 0.7;
      this.strictMode = parsed.strictMode || false;
      this.mistralApiKey = parsed.mistralApiKey;
      this.openaiApiKey = parsed.openaiApiKey;
    }
  }

  saveConfiguration(): void {
    // Sauvegarde dans localStorage
    const config = {
      provider: this.provider,
      model: this.model,
      temperature: this.temperature,
      strictMode: this.strictMode,
      mistralApiKey: this.mistralApiKey,
      openaiApiKey: this.openaiApiKey
    };

    localStorage.setItem('aiChatConfig', JSON.stringify(config));
  }

  clearChat(): void {
    this.messages = [];
    this.error = undefined;
  }
}
```

### Template HTML

**Fichier**: `ui/frontend/src/app/pages/ai-chat/ai-chat.component.html`

```html
<div class="ai-chat-container">
  <!-- Header avec configuration -->
  <div class="chat-header">
    <h2>Assistant IA Professionnel</h2>

    <button mat-icon-button (click)="openConfigDialog()">
      <mat-icon>settings</mat-icon>
    </button>
  </div>

  <!-- Zone de messages -->
  <div class="messages-container" #messagesContainer>
    <div *ngFor="let message of messages"
         class="message"
         [class.user-message]="message.role === 'user'"
         [class.assistant-message]="message.role === 'assistant'">

      <div class="message-avatar">
        <mat-icon *ngIf="message.role === 'user'">person</mat-icon>
        <mat-icon *ngIf="message.role === 'assistant'">smart_toy</mat-icon>
      </div>

      <div class="message-content">
        <div class="message-text" [innerHTML]="message.content | markdown"></div>
        <div class="message-timestamp">{{ message.timestamp | date:'short' }}</div>
      </div>
    </div>

    <!-- Loader pendant le traitement -->
    <div *ngIf="isLoading" class="message assistant-message">
      <div class="message-avatar">
        <mat-icon>smart_toy</mat-icon>
      </div>
      <div class="message-content">
        <mat-spinner diameter="20"></mat-spinner>
        <span>RÃ©flexion en cours...</span>
      </div>
    </div>
  </div>

  <!-- Zone de saisie -->
  <div class="input-container">
    <mat-form-field appearance="outline" class="message-input">
      <mat-label>Votre message</mat-label>
      <textarea matInput
                [(ngModel)]="currentMessage"
                (keydown.enter)="$event.ctrlKey && sendMessage()"
                [disabled]="isLoading"
                rows="3"
                placeholder="Tapez votre message ici... (Ctrl+Enter pour envoyer)">
      </textarea>
    </mat-form-field>

    <button mat-fab
            color="primary"
            (click)="sendMessage()"
            [disabled]="!currentMessage.trim() || isLoading">
      <mat-icon>send</mat-icon>
    </button>
  </div>

  <!-- Affichage des erreurs -->
  <div *ngIf="error" class="error-banner">
    <mat-icon>error</mat-icon>
    {{ error }}
  </div>
</div>
```

---

## Flux de DonnÃ©es Complets

### Exemple 1: AI Chat Agent (Workflow Complet)

```mermaid
sequenceDiagram
    participant User as ğŸ‘¤ Utilisateur
    participant UI as ğŸ–¥ï¸ Angular UI
    participant Agent as ğŸ¤– AI Chat Agent
    participant ClassTool as ğŸ·ï¸ Content Classification
    participant ModTool as ğŸ›¡ï¸ Prompt Moderation
    participant Mistral as ğŸ§  Mistral Connector
    participant API as â˜ï¸ Mistral AI API

    User->>UI: Tape un message
    UI->>UI: Validation frontend

    UI->>Agent: POST /api/v1/chat/completions<br/>{messages, provider, model}

    Note over Agent: Extraction du dernier<br/>message utilisateur

    Agent->>ClassTool: POST /api/v1/classify<br/>{text}
    ClassTool->>ClassTool: Analyse IA
    ClassTool-->>Agent: {is_professional: true, confidence: 0.95}

    Agent->>ModTool: POST /api/v1/moderate/prompt<br/>{prompt, strict_mode}
    ModTool->>ModTool: DÃ©tection contenu<br/>inappropriÃ©
    ModTool-->>Agent: {is_appropriate: true}

    alt Contenu inappropriÃ©
        Agent-->>UI: {success: false, blocked_reason: "..."}
        UI-->>User: âš ï¸ Message bloquÃ©
    else Contenu OK
        Agent->>Mistral: POST /api/v1/mistral/chat<br/>{messages, model}
        Mistral->>API: POST https://api.mistral.ai/v1/chat/completions
        API-->>Mistral: {choices: [...], usage: {...}}
        Mistral-->>Agent: {success: true, message: "..."}

        Agent->>Agent: AgrÃ©gation mÃ©tadonnÃ©es
        Agent-->>UI: {success: true, message, moderation, classification}
        UI-->>User: ğŸ’¬ Affiche la rÃ©ponse
    end
```

### Exemple 2: Document Analyzer (Multi-Tools)

```mermaid
sequenceDiagram
    participant User as ğŸ‘¤ Utilisateur
    participant UI as ğŸ–¥ï¸ Angular UI
    participant Agent as ğŸ“„ Document Analyzer
    participant ExtTool as ğŸ“‘ Document Extractor
    participant WordTool as ğŸ“ Word CRUD
    participant Mistral as ğŸ§  Mistral Connector

    User->>UI: Upload PDF (cahier des charges)
    UI->>Agent: POST /api/v1/analyze/document<br/>{file, analysis_type}

    Agent->>ExtTool: POST /api/v1/extract<br/>{file: PDF}
    ExtTool->>ExtTool: Extraction texte PyPDF2
    ExtTool-->>Agent: {text: "...", pages: 45}

    Note over Agent: DÃ©coupage du texte<br/>en sections

    Agent->>Mistral: POST /api/v1/mistral/chat<br/>{prompt: "Analyse ce CDC"}
    Mistral-->>Agent: {analysis: "...", key_points: [...]}

    Note over Agent: GÃ©nÃ©ration du rapport<br/>structurÃ©

    Agent->>WordTool: POST /api/v1/word/create<br/>{sections, formatting}
    WordTool->>WordTool: CrÃ©ation document python-docx
    WordTool-->>Agent: {file_url: "/files/report.docx"}

    Agent-->>UI: {success: true, analysis, report_url}
    UI-->>User: ğŸ“¥ TÃ©lÃ©charge le rapport
```

### Exemple 3: Web Monitoring Agent (Recherche + SynthÃ¨se)

```mermaid
sequenceDiagram
    participant User as ğŸ‘¤ Utilisateur
    participant UI as ğŸ–¥ï¸ Angular UI
    participant Agent as ğŸ” Web Monitoring
    participant SearchTool as ğŸŒ Web Search Tool
    participant Mistral as ğŸ§  Mistral Connector

    User->>UI: Configure veille<br/>("IA gÃ©nÃ©rative", "hebdo")
    UI->>Agent: POST /api/v1/monitoring/create<br/>{keywords, frequency}

    Note over Agent: Planification (cronjob)

    loop Chaque semaine
        Agent->>SearchTool: POST /api/v1/search<br/>{query: "IA gÃ©nÃ©rative"}
        SearchTool->>SearchTool: DuckDuckGo search
        SearchTool-->>Agent: {results: [{title, url, snippet}]}

        Agent->>SearchTool: POST /api/v1/search/extract<br/>{url: "..."}
        SearchTool->>SearchTool: BeautifulSoup scraping
        SearchTool-->>Agent: {content: "...", links: [...]}

        Note over Agent: AgrÃ©gation des articles

        Agent->>Mistral: POST /api/v1/mistral/chat<br/>{prompt: "SynthÃ©tise ces articles"}
        Mistral-->>Agent: {synthesis: "...", trends: [...]}

        Agent->>Agent: Sauvegarde en BDD
        Agent-->>UI: Notification nouvelle synthÃ¨se
        UI-->>User: ğŸ“§ Email de veille
    end
```

---

## Exemples Pratiques

### Exemple 1: Appeler un Agent depuis le Frontend

```typescript
// ai-chat.component.ts
async callAiChat(): Promise<void> {
  const request: ChatRequest = {
    messages: [
      { role: 'user', content: 'Explique-moi les microservices' }
    ],
    provider: 'mistral',
    model: 'mistral-large-latest',
    temperature: 0.7,
    strict_mode: true
  };

  try {
    const response = await firstValueFrom(
      this.http.post<ChatResponse>(
        `${environment.api.aiChat}/api/v1/chat/completions`,
        request
      )
    );

    if (response.success) {
      console.log('RÃ©ponse IA:', response.message);
      console.log('ModÃ©ration:', response.moderation_metadata);
      console.log('Classification:', response.classification_metadata);
    } else {
      console.error('BloquÃ©:', response.blocked_reason);
    }

  } catch (error) {
    console.error('Erreur API:', error);
  }
}
```

### Exemple 2: Agent Appelant Plusieurs Tools

```python
# document_analyzer/app/services/analyze_service.py

class AnalyzeService:

    @classmethod
    async def analyze_tender(cls, file: UploadFile) -> Dict:
        """Analyse un appel d'offre complet"""

        # 1ï¸âƒ£ Extraction du texte du document
        extracted_text = await cls._extract_document_text(file)

        # 2ï¸âƒ£ Analyse IA du contenu
        analysis = await cls._analyze_with_ai(extracted_text)

        # 3ï¸âƒ£ GÃ©nÃ©ration du rapport Word
        report_url = await cls._generate_word_report(analysis)

        return {
            "success": True,
            "extracted_text_length": len(extracted_text),
            "analysis": analysis,
            "report_url": report_url
        }

    @classmethod
    async def _extract_document_text(cls, file: UploadFile) -> str:
        """Appel au Document Extractor Tool"""

        files = {"file": (file.filename, await file.read(), file.content_type)}

        async with httpx.AsyncClient(timeout=60.0) as client:
            response = await client.post(
                f"{settings.document_extractor_url}/api/v1/extract",
                files=files
            )
            response.raise_for_status()
            data = response.json()
            return data["text"]

    @classmethod
    async def _analyze_with_ai(cls, text: str) -> Dict:
        """Appel au Mistral Connector"""

        prompt = f"""
        Analyse cet appel d'offre et extrais:
        1. L'objet du marchÃ©
        2. Les critÃ¨res de sÃ©lection
        3. Les dÃ©lais
        4. Le budget estimÃ©
        5. Les risques identifiÃ©s

        Texte:
        {text[:10000]}  # Limite Ã  10k caractÃ¨res
        """

        payload = {
            "messages": [
                {"role": "system", "content": "Tu es un expert en analyse d'appels d'offre."},
                {"role": "user", "content": prompt}
            ],
            "model": "mistral-large-latest",
            "temperature": 0.3
        }

        async with httpx.AsyncClient(timeout=120.0) as client:
            response = await client.post(
                f"{settings.mistral_connector_url}/api/v1/mistral/chat",
                json=payload
            )
            response.raise_for_status()
            data = response.json()
            return {
                "analysis_text": data["message"],
                "model_used": data["model"]
            }

    @classmethod
    async def _generate_word_report(cls, analysis: Dict) -> str:
        """Appel au Word CRUD Tool"""

        payload = {
            "title": "Analyse d'Appel d'Offre",
            "sections": [
                {
                    "heading": "RÃ©sumÃ© ExÃ©cutif",
                    "content": analysis["analysis_text"]
                },
                {
                    "heading": "MÃ©tadonnÃ©es",
                    "content": f"ModÃ¨le utilisÃ©: {analysis['model_used']}"
                }
            ]
        }

        async with httpx.AsyncClient(timeout=60.0) as client:
            response = await client.post(
                f"{settings.word_crud_url}/api/v1/word/create",
                json=payload
            )
            response.raise_for_status()
            data = response.json()
            return data["file_url"]
```

### Exemple 3: Gestion d'Erreurs et Retry

```python
# Utilitaire pour retry avec backoff exponentiel

import asyncio
from typing import Callable, Any

async def retry_with_backoff(
    func: Callable,
    max_retries: int = 3,
    initial_delay: float = 1.0,
    backoff_factor: float = 2.0
) -> Any:
    """
    ExÃ©cute une fonction async avec retry et backoff exponentiel

    Args:
        func: Fonction Ã  exÃ©cuter
        max_retries: Nombre max de tentatives
        initial_delay: DÃ©lai initial en secondes
        backoff_factor: Facteur de multiplication du dÃ©lai
    """

    last_exception = None
    delay = initial_delay

    for attempt in range(max_retries):
        try:
            return await func()

        except httpx.TimeoutException as e:
            last_exception = e
            print(f"â±ï¸ Timeout (tentative {attempt + 1}/{max_retries})")

        except httpx.HTTPStatusError as e:
            # Ne pas retry sur les erreurs 4xx (client)
            if 400 <= e.response.status_code < 500:
                raise

            last_exception = e
            print(f"âŒ Erreur HTTP {e.response.status_code} (tentative {attempt + 1}/{max_retries})")

        except Exception as e:
            last_exception = e
            print(f"âŒ Erreur: {e} (tentative {attempt + 1}/{max_retries})")

        # Attente avant retry
        if attempt < max_retries - 1:
            await asyncio.sleep(delay)
            delay *= backoff_factor

    # Toutes les tentatives ont Ã©chouÃ©
    raise last_exception


# Utilisation dans un service

class ChatService:

    @classmethod
    async def call_mistral_with_retry(cls, payload: Dict) -> Dict:
        """Appel Mistral avec retry automatique"""

        async def _call():
            async with httpx.AsyncClient(timeout=120.0) as client:
                response = await client.post(
                    f"{settings.mistral_connector_url}/api/v1/mistral/chat",
                    json=payload
                )
                response.raise_for_status()
                return response.json()

        return await retry_with_backoff(_call, max_retries=3)
```

---

## CrÃ©er un Nouvel Agent

### Guide Ã‰tape par Ã‰tape

#### Ã‰tape 1: CrÃ©er la Structure

```bash
# CrÃ©er le dossier de l'agent
mkdir -p agents/my-new-agent/app/{routers,services,models,middleware}
cd agents/my-new-agent

# CrÃ©er les fichiers de base
touch app/__init__.py
touch app/main.py
touch app/config.py
touch app/routers/__init__.py
touch app/routers/my_router.py
touch app/services/__init__.py
touch app/services/my_service.py
touch app/models/__init__.py
touch app/models/my_models.py
touch requirements.txt
touch Dockerfile
touch README.md
```

#### Ã‰tape 2: DÃ©finir la Configuration

**`app/config.py`**

```python
import os
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    app_name: str = "My New Agent"
    version: str = "1.0.0"

    # URLs des dÃ©pendances (tools et connecteurs)
    web_search_url: str = os.getenv("WEB_SEARCH_URL", "http://web-search-tool:8000")
    mistral_connector_url: str = os.getenv("MISTRAL_CONNECTOR_URL", "http://mistral-connector:8000")

    class Config:
        env_file = ".env"

settings = Settings()
```

#### Ã‰tape 3: CrÃ©er les ModÃ¨les

**`app/models/my_models.py`**

```python
from pydantic import BaseModel, Field
from typing import List, Optional

class MyRequest(BaseModel):
    """ModÃ¨le de requÃªte"""
    query: str = Field(..., min_length=1, description="RequÃªte utilisateur")
    options: Optional[dict] = None

class MyResponse(BaseModel):
    """ModÃ¨le de rÃ©ponse"""
    success: bool
    result: Optional[str] = None
    error: Optional[str] = None
    metadata: Optional[dict] = None
```

#### Ã‰tape 4: ImplÃ©menter le Service

**`app/services/my_service.py`**

```python
import httpx
from app.config import settings
from app.models.my_models import MyRequest, MyResponse

class MyService:
    """Service d'orchestration de l'agent"""

    @classmethod
    async def process(cls, request: MyRequest) -> MyResponse:
        """Traitement principal"""

        try:
            # 1. Appel au Web Search Tool
            search_results = await cls._search_web(request.query)

            # 2. Appel au Mistral Connector pour analyse
            analysis = await cls._analyze_with_ai(search_results)

            return MyResponse(
                success=True,
                result=analysis,
                metadata={
                    "search_results_count": len(search_results)
                }
            )

        except Exception as e:
            return MyResponse(
                success=False,
                error=str(e)
            )

    @classmethod
    async def _search_web(cls, query: str) -> list:
        """Appel au Web Search Tool"""
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(
                f"{settings.web_search_url}/api/v1/search/",
                json={"query": query, "max_results": 5}
            )
            response.raise_for_status()
            data = response.json()
            return data["results"]

    @classmethod
    async def _analyze_with_ai(cls, results: list) -> str:
        """Appel au Mistral Connector"""

        # PrÃ©paration du prompt
        results_text = "\n".join([
            f"- {r['title']}: {r['snippet']}" for r in results
        ])

        payload = {
            "messages": [
                {"role": "user", "content": f"SynthÃ©tise ces rÃ©sultats:\n{results_text}"}
            ],
            "model": "mistral-large-latest"
        }

        async with httpx.AsyncClient(timeout=120.0) as client:
            response = await client.post(
                f"{settings.mistral_connector_url}/api/v1/mistral/chat",
                json=payload
            )
            response.raise_for_status()
            data = response.json()
            return data["message"]
```

#### Ã‰tape 5: CrÃ©er le Router

**`app/routers/my_router.py`**

```python
from fastapi import APIRouter, HTTPException
from app.models.my_models import MyRequest, MyResponse
from app.services.my_service import MyService

router = APIRouter(prefix="/api/v1/agent")

@router.post("/process", response_model=MyResponse)
async def process_request(request: MyRequest) -> MyResponse:
    """Endpoint principal de l'agent"""
    try:
        return await MyService.process(request)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

#### Ã‰tape 6: Point d'EntrÃ©e FastAPI

**`app/main.py`**

```python
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from app.config import settings
from app.routers import my_router

app = FastAPI(
    title=settings.app_name,
    version=settings.version
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Routers
app.include_router(my_router.router, tags=["Agent"])

@app.get("/health")
async def health():
    return {"status": "healthy", "service": settings.app_name}

@app.get("/")
async def root():
    return {
        "service": settings.app_name,
        "version": settings.version
    }
```

#### Ã‰tape 7: Requirements

**`requirements.txt`**

```
fastapi==0.109.0
uvicorn==0.27.0
httpx==0.26.0
pydantic==2.5.3
pydantic-settings==2.1.0
python-multipart==0.0.6
```

#### Ã‰tape 8: Dockerfile

**`Dockerfile`**

```dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY app/ ./app/

EXPOSE 8021

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8021"]
```

#### Ã‰tape 9: Ajouter dans Docker Compose

**`docker-compose.yml`** (Ã  la racine du projet)

```yaml
services:
  # ... autres services ...

  my-new-agent:
    build:
      context: ./agents/my-new-agent
    container_name: my-new-agent
    ports:
      - "8021:8021"
    environment:
      - WEB_SEARCH_URL=http://web-search-tool:8000
      - MISTRAL_CONNECTOR_URL=http://mistral-connector:8000
    depends_on:
      - web-search-tool
      - mistral-connector
    networks:
      - agent-network
    restart: unless-stopped

networks:
  agent-network:
    driver: bridge
```

#### Ã‰tape 10: CrÃ©er la Page Frontend

**`ui/frontend/src/app/pages/my-agent/my-agent.component.ts`**

```typescript
import { Component } from '@angular/core';
import { HttpClient } from '@angular/common/http';
import { environment } from '../../../environments/environment';

@Component({
  selector: 'app-my-agent',
  templateUrl: './my-agent.component.html',
  styleUrls: ['./my-agent.component.scss']
})
export class MyAgentComponent {

  query: string = '';
  result: any = null;
  isLoading: boolean = false;

  constructor(private http: HttpClient) {}

  async processQuery(): Promise<void> {
    if (!this.query.trim()) return;

    this.isLoading = true;

    try {
      this.result = await this.http.post(
        `${environment.api.myAgent}/api/v1/agent/process`,
        { query: this.query }
      ).toPromise();
    } catch (error) {
      console.error('Erreur:', error);
    } finally {
      this.isLoading = false;
    }
  }
}
```

#### Ã‰tape 11: Ajouter au Catalogue

**`ui/frontend/src/app/pages/agents-catalog/agents-catalog.component.ts`**

```typescript
agents: Agent[] = [
  // ... autres agents ...

  {
    id: 'my-new-agent',
    name: 'Mon Nouvel Agent',
    description: 'Description de mon agent',
    icon: 'lightbulb',
    route: '/my-agent',
    hasConfig: false,
    status: 'active'
  }
];
```

#### Ã‰tape 12: Configuration Environment

**`ui/frontend/src/environments/environment.ts`**

```typescript
export const environment = {
  api: {
    // ... autres APIs ...
    myAgent: 'http://localhost:8021'
  }
};
```

#### Ã‰tape 13: Lancer et Tester

```bash
# Build et dÃ©marrage
docker-compose up -d my-new-agent

# VÃ©rifier les logs
docker logs -f my-new-agent

# Tester le health check
curl http://localhost:8021/health

# Tester l'endpoint
curl -X POST http://localhost:8021/api/v1/agent/process \
  -H "Content-Type: application/json" \
  -d '{"query": "test"}'
```

---

## RÃ©sumÃ© Architecture

### ResponsabilitÃ©s par Composant

| Composant | ResponsabilitÃ© | Appelle |
|-----------|---------------|---------|
| **Frontend (Angular)** | Interface utilisateur, stockage config local | Agents uniquement |
| **Agent Orchestrateur** | Logique mÃ©tier, coordination workflow | Tools + Connecteurs |
| **Tool Utilitaire** | Fonction technique isolÃ©e (extraction, CRUD, search) | Rien (ou API externes directement) |
| **Tool de Gouvernance** | ModÃ©ration, classification, sÃ©curitÃ© | Connecteurs IA |
| **Connecteur Central** | Encapsulation API externe, gestion auth | APIs externes uniquement |

### Pattern de Communication

```
Frontend â”€â”€â”€â”€â”€â”€â–º Agent â”€â”€â”€â”€â”€â”€â–º Tool
                   â”‚             â”‚
                   â”‚             â””â”€â”€â–º API Externe (optionnel)
                   â”‚
                   â””â”€â”€â”€â”€â”€â”€â–º Connecteur â”€â”€â”€â”€â”€â”€â–º API Externe
```

### Bonnes Pratiques

âœ… **Ã€ FAIRE**:
- Un agent = une responsabilitÃ© mÃ©tier claire
- Un tool = une fonction technique unique
- Validation Pydantic sur toutes les entrÃ©es/sorties
- Health checks pour Docker
- Gestion d'erreurs avec retry pour les appels HTTP
- Logs structurÃ©s (JSON) pour le monitoring
- Variables d'environnement pour la configuration

âŒ **Ã€ Ã‰VITER**:
- Agent qui appelle un autre agent (crÃ©er un tool partagÃ© Ã  la place)
- Tool qui appelle d'autres tools (sauf cas exceptionnel)
- Logique mÃ©tier dans les routers (mettre dans les services)
- Stockage d'Ã©tat dans les services (stateless uniquement)
- Hardcoder les URLs (utiliser config.py)

---

## Documentation Technique ComplÃ¨te

### Fichiers de RÃ©fÃ©rence

- **Architecture globale**: `/docs/ARCHITECTURE_AGENTS_TOOLS.md` (ce fichier)
- **Docker Compose**: `/docker-compose.yml`
- **Environment Frontend**: `/ui/frontend/src/environments/environment.ts`
- **Catalogue Agents**: `/ui/frontend/src/app/pages/agents-catalog/`

### Ports UtilisÃ©s

| Port | Service | Type |
|------|---------|------|
| 4200 | Frontend Angular | UI |
| 8001 | Word CRUD Tool | Tool |
| 8002 | Web Search Tool | Tool |
| 8003 | PDF CRUD Tool | Tool |
| 8004 | Excel CRUD Tool | Tool |
| 8005 | Mistral Connector | Connecteur |
| 8006 | OpenAI Connector | Connecteur |
| 8007 | File Upload Tool | Tool |
| 8008 | Document Extractor Tool | Tool |
| 8009 | Document Analyzer Agent | Agent |
| 8010 | Appointment Scheduler Agent | Agent |
| 8011 | PPTX CRUD Tool | Tool |
| 8012 | AI Chat Agent | Agent |
| 8013 | Prompt Moderation Tool | Tool |
| 8014 | Content Classification Tool | Tool |
| 8015 | Dolibarr Connector | Connecteur |
| 8016 | Dolibarr Stats Agent | Agent |
| 8017 | Web Monitoring Agent | Agent |
| 8018 | Contract Analysis Agent | Agent |
| 8019 | Email POD Analyzer Agent | Agent |
| 8020 | EML Parser Tool | Tool |
| 8021+ | Nouveaux agents | Agent |

---

**CrÃ©Ã© le**: 2026-01-07
**Version**: 1.0.0
**Auteur**: Agent-PF Team
